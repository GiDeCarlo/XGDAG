{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_ranking_no_LP_intersection' from 'GDARanking' (c:\\Repositories\\XGDAG\\GDARanking.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Repositories\\XGDAG\\Classification_pipeline_new_rankings_binary.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositories/XGDAG/Classification_pipeline_new_rankings_binary.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mCreateDatasetv2_binary\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dataset_from_graph\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositories/XGDAG/Classification_pipeline_new_rankings_binary.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPaths\u001b[39;00m \u001b[39mimport\u001b[39;00m PATH_TO_GRAPHS, PATH_TO_RANKINGS\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Repositories/XGDAG/Classification_pipeline_new_rankings_binary.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mGDARanking\u001b[39;00m \u001b[39mimport\u001b[39;00m get_ranking, get_ranking_from_all_positives, validate_with_extended_dataset, get_ranking_no_LP_intersection\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositories/XGDAG/Classification_pipeline_new_rankings_binary.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mGraphSageModel\u001b[39;00m \u001b[39mimport\u001b[39;00m GNN7L_Sage\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositories/XGDAG/Classification_pipeline_new_rankings_binary.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_ranking_no_LP_intersection' from 'GDARanking' (c:\\Repositories\\XGDAG\\GDARanking.py)"
     ]
    }
   ],
   "source": [
    "from GNNTrain import train, predict_from_saved_model\n",
    "from CreateDatasetv2_binary import get_dataset_from_graph\n",
    "from Paths import PATH_TO_GRAPHS, PATH_TO_RANKINGS\n",
    "from GDARanking import get_ranking, get_ranking_from_all_positives, validate_with_extended_dataset, get_ranking_no_LP_intersection, validate_with_extended_dataset_no_LP\n",
    "from GraphSageModel import GNN7L_Sage\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_Id  = 'C0006142'\n",
    "classes     = ['P', 'U']\n",
    "model_name  = 'GraphSAGE_' + disease_Id + '_new_rankings_binary'\n",
    "graph_path  = PATH_TO_GRAPHS + 'grafo_nedbit_' + disease_Id + '.gml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Reading graph...ok\n",
      "[+] Creating dataset...ok\n",
      "[i] Elapsed time: 28.72\n"
     ]
    }
   ],
   "source": [
    "dataset, G = get_dataset_from_graph(graph_path, disease_Id, quartile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7f99dc921a47d0ba63c66517029117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 0000] train loss: 20.7379, train acc: 0.9312, val loss: 9.2713, val acc: 0.9481  (best train acc: 0.9312, best val acc: 0.9481, best train loss: 20.7379  @ epoch 0 )\n",
      "[Epoch: 0020] train loss: 1.6296, train acc: 0.8947, val loss: 0.3517, val acc: 0.9477  (best train acc: 0.9312, best val acc: 0.9481, best train loss: 1.6296  @ epoch 20 )\n",
      "[Epoch: 0040] train loss: 0.6390, train acc: 0.8987, val loss: 0.2481, val acc: 0.9437  (best train acc: 0.9312, best val acc: 0.9481, best train loss: 0.6390  @ epoch 40 )\n",
      "[Epoch: 0060] train loss: 0.4008, train acc: 0.9223, val loss: 0.2355, val acc: 0.9352  (best train acc: 0.9312, best val acc: 0.9481, best train loss: 0.4008  @ epoch 60 )\n",
      "[Epoch: 0080] train loss: 0.3311, train acc: 0.9087, val loss: 0.2213, val acc: 0.9450  (best train acc: 0.9312, best val acc: 0.9481, best train loss: 0.3288  @ epoch 79 )\n",
      "[Epoch: 0100] train loss: 0.2906, train acc: 0.9297, val loss: 0.2249, val acc: 0.9420  (best train acc: 0.9312, best val acc: 0.9481, best train loss: 0.2887  @ epoch 97 )\n",
      "[Epoch: 0120] train loss: 0.2726, train acc: 0.9323, val loss: 0.2191, val acc: 0.9460  (best train acc: 0.9346, best val acc: 0.9481, best train loss: 0.2682  @ epoch 118 )\n",
      "[Epoch: 0140] train loss: 0.2508, train acc: 0.9370, val loss: 0.2211, val acc: 0.9460  (best train acc: 0.9392, best val acc: 0.9481, best train loss: 0.2508  @ epoch 140 )\n",
      "[Epoch: 0160] train loss: 0.2445, train acc: 0.9361, val loss: 0.2179, val acc: 0.9484  (best train acc: 0.9395, best val acc: 0.9497, best train loss: 0.2429  @ epoch 154 )\n",
      "[Epoch: 0180] train loss: 0.2373, train acc: 0.9401, val loss: 0.2131, val acc: 0.9484  (best train acc: 0.9417, best val acc: 0.9497, best train loss: 0.2317  @ epoch 178 )\n",
      "[Epoch: 0200] train loss: 0.2231, train acc: 0.9421, val loss: 0.2130, val acc: 0.9487  (best train acc: 0.9430, best val acc: 0.9497, best train loss: 0.2231  @ epoch 200 )\n",
      "[Epoch: 0220] train loss: 0.2196, train acc: 0.9413, val loss: 0.2092, val acc: 0.9484  (best train acc: 0.9449, best val acc: 0.9497, best train loss: 0.2163  @ epoch 217 )\n",
      "[Epoch: 0240] train loss: 0.2078, train acc: 0.9429, val loss: 0.1948, val acc: 0.9521  (best train acc: 0.9458, best val acc: 0.9521, best train loss: 0.2037  @ epoch 238 )\n",
      "[Epoch: 0260] train loss: 0.1934, train acc: 0.9459, val loss: 0.1900, val acc: 0.9521  (best train acc: 0.9477, best val acc: 0.9535, best train loss: 0.1926  @ epoch 258 )\n",
      "[Epoch: 0280] train loss: 0.1866, train acc: 0.9472, val loss: 0.1830, val acc: 0.9548  (best train acc: 0.9479, best val acc: 0.9548, best train loss: 0.1861  @ epoch 278 )\n",
      "[Epoch: 0300] train loss: 0.1847, train acc: 0.9486, val loss: 0.1688, val acc: 0.9545  (best train acc: 0.9489, best val acc: 0.9551, best train loss: 0.1810  @ epoch 287 )\n",
      "[Epoch: 0320] train loss: 0.1766, train acc: 0.9489, val loss: 0.1725, val acc: 0.9548  (best train acc: 0.9503, best val acc: 0.9555, best train loss: 0.1754  @ epoch 319 )\n",
      "[Epoch: 0340] train loss: 0.1715, train acc: 0.9511, val loss: 0.1700, val acc: 0.9565  (best train acc: 0.9511, best val acc: 0.9585, best train loss: 0.1715  @ epoch 340 )\n",
      "[Epoch: 0360] train loss: 0.1632, train acc: 0.9510, val loss: 0.1656, val acc: 0.9589  (best train acc: 0.9522, best val acc: 0.9602, best train loss: 0.1632  @ epoch 360 )\n",
      "[Epoch: 0380] train loss: 0.1678, train acc: 0.9513, val loss: 0.1620, val acc: 0.9602  (best train acc: 0.9522, best val acc: 0.9602, best train loss: 0.1632  @ epoch 360 )\n",
      "[Epoch: 0400] train loss: 0.1597, train acc: 0.9522, val loss: 0.1586, val acc: 0.9616  (best train acc: 0.9533, best val acc: 0.9619, best train loss: 0.1596  @ epoch 397 )\n",
      "[Epoch: 0420] train loss: 0.1600, train acc: 0.9514, val loss: 0.1537, val acc: 0.9612  (best train acc: 0.9542, best val acc: 0.9619, best train loss: 0.1540  @ epoch 419 )\n",
      "[Epoch: 0440] train loss: 0.1529, train acc: 0.9539, val loss: 0.1470, val acc: 0.9612  (best train acc: 0.9542, best val acc: 0.9642, best train loss: 0.1529  @ epoch 440 )\n",
      "[Epoch: 0460] train loss: 0.1535, train acc: 0.9533, val loss: 0.1464, val acc: 0.9653  (best train acc: 0.9542, best val acc: 0.9653, best train loss: 0.1509  @ epoch 455 )\n",
      "[Epoch: 0480] train loss: 0.1466, train acc: 0.9554, val loss: 0.1427, val acc: 0.9659  (best train acc: 0.9554, best val acc: 0.9659, best train loss: 0.1466  @ epoch 480 )\n",
      "[Epoch: 0500] train loss: 0.1437, train acc: 0.9568, val loss: 0.1368, val acc: 0.9653  (best train acc: 0.9570, best val acc: 0.9669, best train loss: 0.1424  @ epoch 499 )\n",
      "[Epoch: 0520] train loss: 0.1456, train acc: 0.9562, val loss: 0.1337, val acc: 0.9659  (best train acc: 0.9570, best val acc: 0.9669, best train loss: 0.1401  @ epoch 515 )\n",
      "[Epoch: 0540] train loss: 0.1354, train acc: 0.9578, val loss: 0.1297, val acc: 0.9669  (best train acc: 0.9578, best val acc: 0.9676, best train loss: 0.1354  @ epoch 540 )\n",
      "[Epoch: 0560] train loss: 0.1368, train acc: 0.9586, val loss: 0.1340, val acc: 0.9680  (best train acc: 0.9586, best val acc: 0.9693, best train loss: 0.1336  @ epoch 557 )\n",
      "[Epoch: 0580] train loss: 0.1341, train acc: 0.9579, val loss: 0.1238, val acc: 0.9693  (best train acc: 0.9592, best val acc: 0.9700, best train loss: 0.1302  @ epoch 579 )\n",
      "[Epoch: 0600] train loss: 0.1300, train acc: 0.9578, val loss: 0.1216, val acc: 0.9713  (best train acc: 0.9598, best val acc: 0.9717, best train loss: 0.1250  @ epoch 591 )\n",
      "[Epoch: 0620] train loss: 0.1250, train acc: 0.9606, val loss: 0.1194, val acc: 0.9707  (best train acc: 0.9606, best val acc: 0.9730, best train loss: 0.1250  @ epoch 620 )\n",
      "[Epoch: 0640] train loss: 0.1232, train acc: 0.9602, val loss: 0.1103, val acc: 0.9703  (best train acc: 0.9610, best val acc: 0.9740, best train loss: 0.1224  @ epoch 638 )\n",
      "[Epoch: 0660] train loss: 0.1176, train acc: 0.9620, val loss: 0.1088, val acc: 0.9717  (best train acc: 0.9620, best val acc: 0.9740, best train loss: 0.1176  @ epoch 660 )\n",
      "[Epoch: 0680] train loss: 0.1220, train acc: 0.9592, val loss: 0.1061, val acc: 0.9737  (best train acc: 0.9620, best val acc: 0.9747, best train loss: 0.1168  @ epoch 676 )\n",
      "[Epoch: 0700] train loss: 0.1170, train acc: 0.9620, val loss: 0.0999, val acc: 0.9740  (best train acc: 0.9633, best val acc: 0.9747, best train loss: 0.1118  @ epoch 694 )\n",
      "[Epoch: 0720] train loss: 0.1111, train acc: 0.9634, val loss: 0.0959, val acc: 0.9750  (best train acc: 0.9639, best val acc: 0.9761, best train loss: 0.1109  @ epoch 713 )\n",
      "[Epoch: 0740] train loss: 0.1047, train acc: 0.9651, val loss: 0.0918, val acc: 0.9750  (best train acc: 0.9651, best val acc: 0.9764, best train loss: 0.1040  @ epoch 735 )\n",
      "[Epoch: 0760] train loss: 0.1061, train acc: 0.9620, val loss: 0.0880, val acc: 0.9771  (best train acc: 0.9651, best val acc: 0.9777, best train loss: 0.1018  @ epoch 757 )\n",
      "[Epoch: 0780] train loss: 0.1006, train acc: 0.9636, val loss: 0.0808, val acc: 0.9764  (best train acc: 0.9657, best val acc: 0.9794, best train loss: 0.0963  @ epoch 778 )\n",
      "[Epoch: 0800] train loss: 0.0963, train acc: 0.9656, val loss: 0.0770, val acc: 0.9777  (best train acc: 0.9667, best val acc: 0.9798, best train loss: 0.0919  @ epoch 799 )\n",
      "[Epoch: 0820] train loss: 0.0896, train acc: 0.9665, val loss: 0.0704, val acc: 0.9808  (best train acc: 0.9683, best val acc: 0.9808, best train loss: 0.0870  @ epoch 815 )\n",
      "[Epoch: 0840] train loss: 0.0820, train acc: 0.9697, val loss: 0.0648, val acc: 0.9818  (best train acc: 0.9697, best val acc: 0.9818, best train loss: 0.0820  @ epoch 840 )\n",
      "[Epoch: 0860] train loss: 0.0776, train acc: 0.9713, val loss: 0.0588, val acc: 0.9831  (best train acc: 0.9713, best val acc: 0.9838, best train loss: 0.0776  @ epoch 860 )\n",
      "[Epoch: 0880] train loss: 0.0819, train acc: 0.9662, val loss: 0.0539, val acc: 0.9845  (best train acc: 0.9713, best val acc: 0.9845, best train loss: 0.0769  @ epoch 879 )\n",
      "[Epoch: 0900] train loss: 0.0758, train acc: 0.9704, val loss: 0.0530, val acc: 0.9841  (best train acc: 0.9719, best val acc: 0.9855, best train loss: 0.0730  @ epoch 893 )\n",
      "[Epoch: 0920] train loss: 0.0747, train acc: 0.9702, val loss: 0.0496, val acc: 0.9858  (best train acc: 0.9728, best val acc: 0.9865, best train loss: 0.0702  @ epoch 908 )\n",
      "[Epoch: 0940] train loss: 0.0709, train acc: 0.9722, val loss: 0.0466, val acc: 0.9872  (best train acc: 0.9734, best val acc: 0.9872, best train loss: 0.0656  @ epoch 934 )\n",
      "[Epoch: 0960] train loss: 0.0695, train acc: 0.9712, val loss: 0.0490, val acc: 0.9872  (best train acc: 0.9738, best val acc: 0.9875, best train loss: 0.0647  @ epoch 951 )\n",
      "[Epoch: 0980] train loss: 0.0682, train acc: 0.9716, val loss: 0.0450, val acc: 0.9872  (best train acc: 0.9750, best val acc: 0.9882, best train loss: 0.0621  @ epoch 968 )\n",
      "[Epoch: 1000] train loss: 0.0657, train acc: 0.9737, val loss: 0.0424, val acc: 0.9885  (best train acc: 0.9759, best val acc: 0.9885, best train loss: 0.0617  @ epoch 987 )\n",
      "[Epoch: 1020] train loss: 0.0620, train acc: 0.9750, val loss: 0.0409, val acc: 0.9889  (best train acc: 0.9766, best val acc: 0.9889, best train loss: 0.0601  @ epoch 1005 )\n",
      "[Epoch: 1040] train loss: 0.0653, train acc: 0.9725, val loss: 0.0395, val acc: 0.9892  (best train acc: 0.9766, best val acc: 0.9892, best train loss: 0.0599  @ epoch 1034 )\n",
      "[Epoch: 1060] train loss: 0.0648, train acc: 0.9710, val loss: 0.0400, val acc: 0.9892  (best train acc: 0.9773, best val acc: 0.9899, best train loss: 0.0589  @ epoch 1051 )\n",
      "[Epoch: 1080] train loss: 0.0579, train acc: 0.9758, val loss: 0.0402, val acc: 0.9889  (best train acc: 0.9778, best val acc: 0.9899, best train loss: 0.0566  @ epoch 1071 )\n",
      "[Epoch: 1100] train loss: 0.0565, train acc: 0.9767, val loss: 0.0415, val acc: 0.9875  (best train acc: 0.9782, best val acc: 0.9899, best train loss: 0.0557  @ epoch 1090 )\n",
      "[Epoch: 1120] train loss: 0.0587, train acc: 0.9753, val loss: 0.0396, val acc: 0.9889  (best train acc: 0.9782, best val acc: 0.9899, best train loss: 0.0553  @ epoch 1103 )\n",
      "[Epoch: 1140] train loss: 0.0567, train acc: 0.9789, val loss: 0.0366, val acc: 0.9899  (best train acc: 0.9798, best val acc: 0.9902, best train loss: 0.0532  @ epoch 1137 )\n",
      "[Epoch: 1160] train loss: 0.0573, train acc: 0.9764, val loss: 0.0350, val acc: 0.9906  (best train acc: 0.9798, best val acc: 0.9906, best train loss: 0.0532  @ epoch 1137 )\n",
      "[Epoch: 1180] train loss: 0.0541, train acc: 0.9774, val loss: 0.0351, val acc: 0.9899  (best train acc: 0.9798, best val acc: 0.9912, best train loss: 0.0515  @ epoch 1178 )\n",
      "[Epoch: 1200] train loss: 0.0538, train acc: 0.9774, val loss: 0.0377, val acc: 0.9899  (best train acc: 0.9801, best val acc: 0.9922, best train loss: 0.0514  @ epoch 1190 )\n",
      "[Epoch: 1220] train loss: 0.0513, train acc: 0.9786, val loss: 0.0377, val acc: 0.9902  (best train acc: 0.9801, best val acc: 0.9922, best train loss: 0.0513  @ epoch 1220 )\n",
      "[Epoch: 1240] train loss: 0.0537, train acc: 0.9777, val loss: 0.0375, val acc: 0.9909  (best train acc: 0.9801, best val acc: 0.9922, best train loss: 0.0480  @ epoch 1222 )\n",
      "[Epoch: 1260] train loss: 0.0518, train acc: 0.9781, val loss: 0.0365, val acc: 0.9916  (best train acc: 0.9806, best val acc: 0.9922, best train loss: 0.0480  @ epoch 1222 )\n",
      "[Epoch: 1280] train loss: 0.0519, train acc: 0.9794, val loss: 0.0345, val acc: 0.9919  (best train acc: 0.9808, best val acc: 0.9929, best train loss: 0.0480  @ epoch 1222 )\n",
      "[Epoch: 1300] train loss: 0.0488, train acc: 0.9802, val loss: 0.0330, val acc: 0.9922  (best train acc: 0.9808, best val acc: 0.9929, best train loss: 0.0480  @ epoch 1222 )\n",
      "[Epoch: 1320] train loss: 0.0534, train acc: 0.9771, val loss: 0.0357, val acc: 0.9926  (best train acc: 0.9826, best val acc: 0.9929, best train loss: 0.0462  @ epoch 1313 )\n",
      "[Epoch: 1340] train loss: 0.0478, train acc: 0.9819, val loss: 0.0344, val acc: 0.9933  (best train acc: 0.9831, best val acc: 0.9936, best train loss: 0.0462  @ epoch 1313 )\n",
      "[Epoch: 1360] train loss: 0.0493, train acc: 0.9816, val loss: 0.0326, val acc: 0.9939  (best train acc: 0.9831, best val acc: 0.9939, best train loss: 0.0448  @ epoch 1343 )\n",
      "[Epoch: 1380] train loss: 0.0454, train acc: 0.9811, val loss: 0.0334, val acc: 0.9926  (best train acc: 0.9831, best val acc: 0.9939, best train loss: 0.0443  @ epoch 1370 )\n",
      "[Epoch: 1400] train loss: 0.0458, train acc: 0.9824, val loss: 0.0344, val acc: 0.9929  (best train acc: 0.9831, best val acc: 0.9939, best train loss: 0.0443  @ epoch 1370 )\n",
      "[Epoch: 1420] train loss: 0.0451, train acc: 0.9829, val loss: 0.0332, val acc: 0.9936  (best train acc: 0.9841, best val acc: 0.9939, best train loss: 0.0419  @ epoch 1412 )\n",
      "[Epoch: 1440] train loss: 0.0428, train acc: 0.9815, val loss: 0.0332, val acc: 0.9933  (best train acc: 0.9844, best val acc: 0.9946, best train loss: 0.0419  @ epoch 1412 )\n",
      "[Epoch: 1460] train loss: 0.0417, train acc: 0.9831, val loss: 0.0343, val acc: 0.9949  (best train acc: 0.9850, best val acc: 0.9949, best train loss: 0.0407  @ epoch 1457 )\n",
      "[Epoch: 1480] train loss: 0.0420, train acc: 0.9842, val loss: 0.0340, val acc: 0.9943  (best train acc: 0.9851, best val acc: 0.9953, best train loss: 0.0383  @ epoch 1465 )\n",
      "[Epoch: 1500] train loss: 0.0430, train acc: 0.9842, val loss: 0.0336, val acc: 0.9946  (best train acc: 0.9856, best val acc: 0.9953, best train loss: 0.0383  @ epoch 1465 )\n",
      "[Epoch: 1520] train loss: 0.0373, train acc: 0.9853, val loss: 0.0322, val acc: 0.9943  (best train acc: 0.9873, best val acc: 0.9953, best train loss: 0.0363  @ epoch 1513 )\n",
      "[Epoch: 1540] train loss: 0.0380, train acc: 0.9855, val loss: 0.0333, val acc: 0.9956  (best train acc: 0.9873, best val acc: 0.9960, best train loss: 0.0363  @ epoch 1513 )\n",
      "[Epoch: 1560] train loss: 0.0372, train acc: 0.9853, val loss: 0.0318, val acc: 0.9960  (best train acc: 0.9873, best val acc: 0.9960, best train loss: 0.0362  @ epoch 1558 )\n",
      "[Epoch: 1580] train loss: 0.0381, train acc: 0.9858, val loss: 0.0316, val acc: 0.9960  (best train acc: 0.9878, best val acc: 0.9963, best train loss: 0.0343  @ epoch 1570 )\n",
      "[Epoch: 1600] train loss: 0.0349, train acc: 0.9873, val loss: 0.0319, val acc: 0.9949  (best train acc: 0.9880, best val acc: 0.9963, best train loss: 0.0328  @ epoch 1588 )\n",
      "[Epoch: 1620] train loss: 0.0359, train acc: 0.9856, val loss: 0.0305, val acc: 0.9949  (best train acc: 0.9882, best val acc: 0.9963, best train loss: 0.0328  @ epoch 1588 )\n",
      "[Epoch: 1640] train loss: 0.0349, train acc: 0.9872, val loss: 0.0302, val acc: 0.9949  (best train acc: 0.9893, best val acc: 0.9963, best train loss: 0.0326  @ epoch 1630 )\n",
      "[Epoch: 1660] train loss: 0.0369, train acc: 0.9861, val loss: 0.0303, val acc: 0.9949  (best train acc: 0.9893, best val acc: 0.9963, best train loss: 0.0317  @ epoch 1659 )\n",
      "[Epoch: 1680] train loss: 0.0353, train acc: 0.9871, val loss: 0.0303, val acc: 0.9953  (best train acc: 0.9893, best val acc: 0.9963, best train loss: 0.0300  @ epoch 1676 )\n",
      "[Epoch: 1700] train loss: 0.0326, train acc: 0.9879, val loss: 0.0312, val acc: 0.9963  (best train acc: 0.9893, best val acc: 0.9963, best train loss: 0.0300  @ epoch 1676 )\n",
      "[Epoch: 1720] train loss: 0.0327, train acc: 0.9887, val loss: 0.0298, val acc: 0.9963  (best train acc: 0.9901, best val acc: 0.9963, best train loss: 0.0300  @ epoch 1676 )\n",
      "[Epoch: 1740] train loss: 0.0325, train acc: 0.9893, val loss: 0.0293, val acc: 0.9956  (best train acc: 0.9901, best val acc: 0.9963, best train loss: 0.0296  @ epoch 1726 )\n",
      "[Epoch: 1760] train loss: 0.0317, train acc: 0.9884, val loss: 0.0287, val acc: 0.9956  (best train acc: 0.9902, best val acc: 0.9963, best train loss: 0.0294  @ epoch 1756 )\n",
      "[Epoch: 1780] train loss: 0.0294, train acc: 0.9904, val loss: 0.0286, val acc: 0.9960  (best train acc: 0.9909, best val acc: 0.9963, best train loss: 0.0280  @ epoch 1764 )\n",
      "[Epoch: 1800] train loss: 0.0321, train acc: 0.9892, val loss: 0.0285, val acc: 0.9960  (best train acc: 0.9915, best val acc: 0.9963, best train loss: 0.0253  @ epoch 1797 )\n",
      "[Epoch: 1820] train loss: 0.0291, train acc: 0.9901, val loss: 0.0278, val acc: 0.9956  (best train acc: 0.9916, best val acc: 0.9963, best train loss: 0.0253  @ epoch 1797 )\n",
      "[Epoch: 1840] train loss: 0.0275, train acc: 0.9918, val loss: 0.0275, val acc: 0.9956  (best train acc: 0.9918, best val acc: 0.9963, best train loss: 0.0253  @ epoch 1797 )\n",
      "[Epoch: 1860] train loss: 0.0285, train acc: 0.9902, val loss: 0.0266, val acc: 0.9960  (best train acc: 0.9918, best val acc: 0.9963, best train loss: 0.0253  @ epoch 1797 )\n",
      "[Epoch: 1880] train loss: 0.0290, train acc: 0.9898, val loss: 0.0272, val acc: 0.9956  (best train acc: 0.9918, best val acc: 0.9963, best train loss: 0.0253  @ epoch 1797 )\n",
      "[Epoch: 1900] train loss: 0.0279, train acc: 0.9905, val loss: 0.0265, val acc: 0.9963  (best train acc: 0.9918, best val acc: 0.9963, best train loss: 0.0253  @ epoch 1797 )\n",
      "[Epoch: 1920] train loss: 0.0285, train acc: 0.9906, val loss: 0.0256, val acc: 0.9960  (best train acc: 0.9925, best val acc: 0.9966, best train loss: 0.0253  @ epoch 1797 )\n",
      "[Epoch: 1940] train loss: 0.0282, train acc: 0.9910, val loss: 0.0286, val acc: 0.9963  (best train acc: 0.9926, best val acc: 0.9970, best train loss: 0.0247  @ epoch 1930 )\n",
      "[Epoch: 1960] train loss: 0.0273, train acc: 0.9916, val loss: 0.0258, val acc: 0.9960  (best train acc: 0.9926, best val acc: 0.9970, best train loss: 0.0247  @ epoch 1930 )\n",
      "[Epoch: 1980] train loss: 0.0265, train acc: 0.9917, val loss: 0.0245, val acc: 0.9966  (best train acc: 0.9935, best val acc: 0.9970, best train loss: 0.0227  @ epoch 1970 )\n",
      "[Epoch: 2000] train loss: 0.0239, train acc: 0.9924, val loss: 0.0245, val acc: 0.9966  (best train acc: 0.9935, best val acc: 0.9970, best train loss: 0.0227  @ epoch 1970 )\n",
      "[Epoch: 2020] train loss: 0.0280, train acc: 0.9914, val loss: 0.0245, val acc: 0.9963  (best train acc: 0.9935, best val acc: 0.9970, best train loss: 0.0227  @ epoch 1970 )\n",
      "[Epoch: 2040] train loss: 0.0292, train acc: 0.9901, val loss: 0.0232, val acc: 0.9970  (best train acc: 0.9938, best val acc: 0.9970, best train loss: 0.0227  @ epoch 1970 )\n",
      "[Epoch: 2060] train loss: 0.0244, train acc: 0.9924, val loss: 0.0249, val acc: 0.9963  (best train acc: 0.9938, best val acc: 0.9970, best train loss: 0.0227  @ epoch 1970 )\n",
      "[Epoch: 2080] train loss: 0.0263, train acc: 0.9915, val loss: 0.0226, val acc: 0.9970  (best train acc: 0.9938, best val acc: 0.9973, best train loss: 0.0227  @ epoch 1970 )\n",
      "[Epoch: 2100] train loss: 0.0269, train acc: 0.9917, val loss: 0.0233, val acc: 0.9963  (best train acc: 0.9939, best val acc: 0.9973, best train loss: 0.0215  @ epoch 2097 )\n",
      "[Epoch: 2120] train loss: 0.0250, train acc: 0.9921, val loss: 0.0221, val acc: 0.9966  (best train acc: 0.9939, best val acc: 0.9973, best train loss: 0.0215  @ epoch 2097 )\n",
      "[Epoch: 2140] train loss: 0.0263, train acc: 0.9916, val loss: 0.0239, val acc: 0.9963  (best train acc: 0.9941, best val acc: 0.9973, best train loss: 0.0215  @ epoch 2097 )\n",
      "[Epoch: 2160] train loss: 0.0245, train acc: 0.9920, val loss: 0.0226, val acc: 0.9966  (best train acc: 0.9941, best val acc: 0.9973, best train loss: 0.0208  @ epoch 2141 )\n",
      "[Epoch: 2180] train loss: 0.0236, train acc: 0.9932, val loss: 0.0212, val acc: 0.9970  (best train acc: 0.9941, best val acc: 0.9973, best train loss: 0.0197  @ epoch 2173 )\n",
      "[Epoch: 2200] train loss: 0.0227, train acc: 0.9928, val loss: 0.0216, val acc: 0.9963  (best train acc: 0.9941, best val acc: 0.9973, best train loss: 0.0197  @ epoch 2173 )\n",
      "[Epoch: 2220] train loss: 0.0233, train acc: 0.9926, val loss: 0.0205, val acc: 0.9966  (best train acc: 0.9942, best val acc: 0.9973, best train loss: 0.0197  @ epoch 2205 )\n",
      "[Epoch: 2240] train loss: 0.0223, train acc: 0.9938, val loss: 0.0214, val acc: 0.9966  (best train acc: 0.9949, best val acc: 0.9973, best train loss: 0.0197  @ epoch 2224 )\n",
      "[Epoch: 2260] train loss: 0.0217, train acc: 0.9939, val loss: 0.0213, val acc: 0.9966  (best train acc: 0.9949, best val acc: 0.9973, best train loss: 0.0194  @ epoch 2258 )\n",
      "[Epoch: 2280] train loss: 0.0208, train acc: 0.9933, val loss: 0.0208, val acc: 0.9970  (best train acc: 0.9949, best val acc: 0.9973, best train loss: 0.0194  @ epoch 2258 )\n",
      "[Epoch: 2300] train loss: 0.0190, train acc: 0.9955, val loss: 0.0202, val acc: 0.9973  (best train acc: 0.9955, best val acc: 0.9973, best train loss: 0.0190  @ epoch 2300 )\n",
      "[Epoch: 2320] train loss: 0.0232, train acc: 0.9923, val loss: 0.0203, val acc: 0.9970  (best train acc: 0.9955, best val acc: 0.9976, best train loss: 0.0190  @ epoch 2300 )\n",
      "[Epoch: 2340] train loss: 0.0203, train acc: 0.9933, val loss: 0.0204, val acc: 0.9966  (best train acc: 0.9955, best val acc: 0.9976, best train loss: 0.0185  @ epoch 2337 )\n",
      "[Epoch: 2360] train loss: 0.0178, train acc: 0.9954, val loss: 0.0184, val acc: 0.9976  (best train acc: 0.9955, best val acc: 0.9976, best train loss: 0.0178  @ epoch 2360 )\n",
      "[Epoch: 2380] train loss: 0.0201, train acc: 0.9936, val loss: 0.0193, val acc: 0.9976  (best train acc: 0.9955, best val acc: 0.9976, best train loss: 0.0178  @ epoch 2360 )\n",
      "[Epoch: 2400] train loss: 0.0219, train acc: 0.9939, val loss: 0.0187, val acc: 0.9970  (best train acc: 0.9955, best val acc: 0.9976, best train loss: 0.0178  @ epoch 2360 )\n",
      "[Epoch: 2420] train loss: 0.0184, train acc: 0.9952, val loss: 0.0189, val acc: 0.9973  (best train acc: 0.9955, best val acc: 0.9980, best train loss: 0.0172  @ epoch 2407 )\n",
      "[Epoch: 2440] train loss: 0.0180, train acc: 0.9953, val loss: 0.0183, val acc: 0.9980  (best train acc: 0.9959, best val acc: 0.9980, best train loss: 0.0166  @ epoch 2428 )\n",
      "[Epoch: 2460] train loss: 0.0196, train acc: 0.9944, val loss: 0.0181, val acc: 0.9976  (best train acc: 0.9959, best val acc: 0.9980, best train loss: 0.0166  @ epoch 2428 )\n",
      "[Epoch: 2480] train loss: 0.0181, train acc: 0.9947, val loss: 0.0182, val acc: 0.9976  (best train acc: 0.9959, best val acc: 0.9980, best train loss: 0.0155  @ epoch 2475 )\n",
      "[Epoch: 2500] train loss: 0.0155, train acc: 0.9961, val loss: 0.0182, val acc: 0.9976  (best train acc: 0.9961, best val acc: 0.9980, best train loss: 0.0148  @ epoch 2497 )\n",
      "[Epoch: 2520] train loss: 0.0191, train acc: 0.9943, val loss: 0.0187, val acc: 0.9976  (best train acc: 0.9961, best val acc: 0.9980, best train loss: 0.0148  @ epoch 2497 )\n",
      "[Epoch: 2540] train loss: 0.0196, train acc: 0.9944, val loss: 0.0169, val acc: 0.9976  (best train acc: 0.9961, best val acc: 0.9980, best train loss: 0.0148  @ epoch 2497 )\n",
      "[Epoch: 2560] train loss: 0.0193, train acc: 0.9946, val loss: 0.0176, val acc: 0.9980  (best train acc: 0.9961, best val acc: 0.9980, best train loss: 0.0148  @ epoch 2497 )\n",
      "[Epoch: 2580] train loss: 0.0176, train acc: 0.9960, val loss: 0.0180, val acc: 0.9980  (best train acc: 0.9961, best val acc: 0.9980, best train loss: 0.0147  @ epoch 2561 )\n",
      "[Epoch: 2600] train loss: 0.0166, train acc: 0.9952, val loss: 0.0180, val acc: 0.9976  (best train acc: 0.9962, best val acc: 0.9980, best train loss: 0.0147  @ epoch 2561 )\n",
      "[Epoch: 2620] train loss: 0.0161, train acc: 0.9949, val loss: 0.0174, val acc: 0.9976  (best train acc: 0.9962, best val acc: 0.9980, best train loss: 0.0147  @ epoch 2561 )\n",
      "[Epoch: 2640] train loss: 0.0172, train acc: 0.9948, val loss: 0.0170, val acc: 0.9980  (best train acc: 0.9962, best val acc: 0.9983, best train loss: 0.0147  @ epoch 2561 )\n",
      "[Epoch: 2660] train loss: 0.0164, train acc: 0.9952, val loss: 0.0175, val acc: 0.9976  (best train acc: 0.9962, best val acc: 0.9983, best train loss: 0.0147  @ epoch 2561 )\n",
      "[Epoch: 2680] train loss: 0.0156, train acc: 0.9961, val loss: 0.0175, val acc: 0.9973  (best train acc: 0.9965, best val acc: 0.9983, best train loss: 0.0147  @ epoch 2561 )\n",
      "[Epoch: 2700] train loss: 0.0175, train acc: 0.9947, val loss: 0.0174, val acc: 0.9980  (best train acc: 0.9965, best val acc: 0.9983, best train loss: 0.0147  @ epoch 2561 )\n",
      "[Epoch: 2720] train loss: 0.0164, train acc: 0.9957, val loss: 0.0175, val acc: 0.9980  (best train acc: 0.9965, best val acc: 0.9983, best train loss: 0.0147  @ epoch 2561 )\n",
      "[Epoch: 2740] train loss: 0.0174, train acc: 0.9951, val loss: 0.0170, val acc: 0.9976  (best train acc: 0.9965, best val acc: 0.9983, best train loss: 0.0137  @ epoch 2730 )\n",
      "[Epoch: 2760] train loss: 0.0188, train acc: 0.9946, val loss: 0.0182, val acc: 0.9976  (best train acc: 0.9965, best val acc: 0.9983, best train loss: 0.0137  @ epoch 2730 )\n",
      "[Epoch: 2780] train loss: 0.0174, train acc: 0.9950, val loss: 0.0175, val acc: 0.9980  (best train acc: 0.9965, best val acc: 0.9983, best train loss: 0.0137  @ epoch 2730 )\n",
      "[Epoch: 2800] train loss: 0.0176, train acc: 0.9951, val loss: 0.0174, val acc: 0.9976  (best train acc: 0.9965, best val acc: 0.9983, best train loss: 0.0137  @ epoch 2730 )\n",
      "[Epoch: 2820] train loss: 0.0155, train acc: 0.9956, val loss: 0.0177, val acc: 0.9973  (best train acc: 0.9965, best val acc: 0.9983, best train loss: 0.0129  @ epoch 2801 )\n",
      "[Epoch: 2840] train loss: 0.0120, train acc: 0.9965, val loss: 0.0175, val acc: 0.9976  (best train acc: 0.9965, best val acc: 0.9983, best train loss: 0.0120  @ epoch 2840 )\n",
      "[Epoch: 2860] train loss: 0.0109, train acc: 0.9965, val loss: 0.0174, val acc: 0.9983  (best train acc: 0.9975, best val acc: 0.9983, best train loss: 0.0109  @ epoch 2860 )\n",
      "[Epoch: 2880] train loss: 0.0119, train acc: 0.9968, val loss: 0.0180, val acc: 0.9980  (best train acc: 0.9976, best val acc: 0.9983, best train loss: 0.0101  @ epoch 2876 )\n",
      "[Epoch: 2900] train loss: 0.0101, train acc: 0.9971, val loss: 0.0171, val acc: 0.9983  (best train acc: 0.9981, best val acc: 0.9983, best train loss: 0.0087  @ epoch 2890 )\n",
      "[Epoch: 2920] train loss: 0.0102, train acc: 0.9976, val loss: 0.0169, val acc: 0.9980  (best train acc: 0.9981, best val acc: 0.9983, best train loss: 0.0087  @ epoch 2890 )\n",
      "[Epoch: 2940] train loss: 0.0098, train acc: 0.9975, val loss: 0.0182, val acc: 0.9980  (best train acc: 0.9981, best val acc: 0.9983, best train loss: 0.0087  @ epoch 2890 )\n",
      "[Epoch: 2960] train loss: 0.0119, train acc: 0.9973, val loss: 0.0174, val acc: 0.9980  (best train acc: 0.9982, best val acc: 0.9983, best train loss: 0.0085  @ epoch 2949 )\n",
      "[Epoch: 2980] train loss: 0.0104, train acc: 0.9975, val loss: 0.0183, val acc: 0.9976  (best train acc: 0.9982, best val acc: 0.9983, best train loss: 0.0085  @ epoch 2949 )\n",
      "[Epoch: 3000] train loss: 0.0111, train acc: 0.9974, val loss: 0.0173, val acc: 0.9980  (best train acc: 0.9983, best val acc: 0.9983, best train loss: 0.0080  @ epoch 2983 )\n",
      "[Epoch: 3020] train loss: 0.0090, train acc: 0.9980, val loss: 0.0169, val acc: 0.9980  (best train acc: 0.9983, best val acc: 0.9983, best train loss: 0.0080  @ epoch 2983 )\n",
      "[Epoch: 3040] train loss: 0.0118, train acc: 0.9967, val loss: 0.0174, val acc: 0.9980  (best train acc: 0.9985, best val acc: 0.9983, best train loss: 0.0075  @ epoch 3035 )\n",
      "[Epoch: 3060] train loss: 0.0115, train acc: 0.9970, val loss: 0.0168, val acc: 0.9980  (best train acc: 0.9985, best val acc: 0.9983, best train loss: 0.0075  @ epoch 3035 )\n",
      "[Epoch: 3080] train loss: 0.0119, train acc: 0.9967, val loss: 0.0167, val acc: 0.9983  (best train acc: 0.9985, best val acc: 0.9983, best train loss: 0.0075  @ epoch 3035 )\n",
      "[Epoch: 3100] train loss: 0.0110, train acc: 0.9970, val loss: 0.0174, val acc: 0.9983  (best train acc: 0.9986, best val acc: 0.9983, best train loss: 0.0070  @ epoch 3097 )\n",
      "[Epoch: 3120] train loss: 0.0087, train acc: 0.9981, val loss: 0.0172, val acc: 0.9983  (best train acc: 0.9987, best val acc: 0.9983, best train loss: 0.0070  @ epoch 3097 )\n",
      "[Epoch: 3140] train loss: 0.0121, train acc: 0.9967, val loss: 0.0172, val acc: 0.9983  (best train acc: 0.9987, best val acc: 0.9983, best train loss: 0.0070  @ epoch 3097 )\n",
      "[Epoch: 3160] train loss: 0.0102, train acc: 0.9967, val loss: 0.0178, val acc: 0.9980  (best train acc: 0.9987, best val acc: 0.9983, best train loss: 0.0070  @ epoch 3097 )\n",
      "[Epoch: 3180] train loss: 0.0100, train acc: 0.9977, val loss: 0.0159, val acc: 0.9983  (best train acc: 0.9987, best val acc: 0.9983, best train loss: 0.0070  @ epoch 3097 )\n",
      "[Epoch: 3200] train loss: 0.0085, train acc: 0.9981, val loss: 0.0163, val acc: 0.9983  (best train acc: 0.9987, best val acc: 0.9983, best train loss: 0.0070  @ epoch 3097 )\n",
      "[Epoch: 3220] train loss: 0.0077, train acc: 0.9983, val loss: 0.0166, val acc: 0.9983  (best train acc: 0.9987, best val acc: 0.9983, best train loss: 0.0070  @ epoch 3097 )\n",
      "[Epoch: 3240] train loss: 0.0091, train acc: 0.9983, val loss: 0.0170, val acc: 0.9980  (best train acc: 0.9987, best val acc: 0.9983, best train loss: 0.0070  @ epoch 3097 )\n",
      "[Epoch: 3260] train loss: 0.0102, train acc: 0.9973, val loss: 0.0163, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3280] train loss: 0.0097, train acc: 0.9980, val loss: 0.0159, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3300] train loss: 0.0106, train acc: 0.9978, val loss: 0.0170, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3320] train loss: 0.0103, train acc: 0.9979, val loss: 0.0172, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3340] train loss: 0.0094, train acc: 0.9979, val loss: 0.0171, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3360] train loss: 0.0093, train acc: 0.9979, val loss: 0.0174, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3380] train loss: 0.0098, train acc: 0.9978, val loss: 0.0174, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3400] train loss: 0.0130, train acc: 0.9968, val loss: 0.0170, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3420] train loss: 0.0090, train acc: 0.9980, val loss: 0.0155, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3440] train loss: 0.0085, train acc: 0.9980, val loss: 0.0167, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3460] train loss: 0.0107, train acc: 0.9975, val loss: 0.0159, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3480] train loss: 0.0105, train acc: 0.9975, val loss: 0.0158, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3500] train loss: 0.0073, train acc: 0.9986, val loss: 0.0158, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3520] train loss: 0.0081, train acc: 0.9980, val loss: 0.0160, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3540] train loss: 0.0092, train acc: 0.9980, val loss: 0.0154, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3560] train loss: 0.0106, train acc: 0.9978, val loss: 0.0159, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3580] train loss: 0.0107, train acc: 0.9974, val loss: 0.0153, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3600] train loss: 0.0083, train acc: 0.9983, val loss: 0.0158, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3620] train loss: 0.0111, train acc: 0.9973, val loss: 0.0160, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3640] train loss: 0.0092, train acc: 0.9981, val loss: 0.0157, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3660] train loss: 0.0085, train acc: 0.9979, val loss: 0.0153, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3680] train loss: 0.0080, train acc: 0.9985, val loss: 0.0159, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9983, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3700] train loss: 0.0089, train acc: 0.9985, val loss: 0.0158, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3720] train loss: 0.0081, train acc: 0.9986, val loss: 0.0154, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3740] train loss: 0.0079, train acc: 0.9982, val loss: 0.0146, val acc: 0.9987  (best train acc: 0.9988, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3760] train loss: 0.0092, train acc: 0.9977, val loss: 0.0144, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3780] train loss: 0.0076, train acc: 0.9980, val loss: 0.0153, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3800] train loss: 0.0109, train acc: 0.9974, val loss: 0.0164, val acc: 0.9980  (best train acc: 0.9988, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3820] train loss: 0.0085, train acc: 0.9980, val loss: 0.0150, val acc: 0.9983  (best train acc: 0.9988, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3840] train loss: 0.0064, train acc: 0.9989, val loss: 0.0155, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3860] train loss: 0.0109, train acc: 0.9974, val loss: 0.0145, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3880] train loss: 0.0096, train acc: 0.9977, val loss: 0.0159, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3900] train loss: 0.0073, train acc: 0.9981, val loss: 0.0160, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3920] train loss: 0.0094, train acc: 0.9980, val loss: 0.0141, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3940] train loss: 0.0082, train acc: 0.9982, val loss: 0.0156, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0063  @ epoch 3253 )\n",
      "[Epoch: 3960] train loss: 0.0119, train acc: 0.9967, val loss: 0.0152, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0061  @ epoch 3948 )\n",
      "[Epoch: 3980] train loss: 0.0071, train acc: 0.9983, val loss: 0.0148, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0061  @ epoch 3948 )\n",
      "[Epoch: 4000] train loss: 0.0086, train acc: 0.9979, val loss: 0.0158, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0061  @ epoch 3948 )\n",
      "[Epoch: 4020] train loss: 0.0096, train acc: 0.9978, val loss: 0.0154, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0061  @ epoch 3948 )\n",
      "[Epoch: 4040] train loss: 0.0099, train acc: 0.9975, val loss: 0.0145, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0061  @ epoch 3948 )\n",
      "[Epoch: 4060] train loss: 0.0084, train acc: 0.9980, val loss: 0.0151, val acc: 0.9983  (best train acc: 0.9989, best val acc: 0.9987, best train loss: 0.0061  @ epoch 3948 )\n",
      "[Epoch: 4080] train loss: 0.0069, train acc: 0.9984, val loss: 0.0147, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4100] train loss: 0.0094, train acc: 0.9977, val loss: 0.0138, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4120] train loss: 0.0079, train acc: 0.9981, val loss: 0.0146, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4140] train loss: 0.0093, train acc: 0.9978, val loss: 0.0154, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4160] train loss: 0.0098, train acc: 0.9977, val loss: 0.0135, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4180] train loss: 0.0100, train acc: 0.9972, val loss: 0.0138, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4200] train loss: 0.0097, train acc: 0.9980, val loss: 0.0126, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4220] train loss: 0.0080, train acc: 0.9982, val loss: 0.0154, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4240] train loss: 0.0074, train acc: 0.9983, val loss: 0.0146, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4260] train loss: 0.0090, train acc: 0.9982, val loss: 0.0149, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4280] train loss: 0.0080, train acc: 0.9983, val loss: 0.0142, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4300] train loss: 0.0082, train acc: 0.9980, val loss: 0.0146, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4320] train loss: 0.0089, train acc: 0.9978, val loss: 0.0138, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4340] train loss: 0.0088, train acc: 0.9983, val loss: 0.0151, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4360] train loss: 0.0086, train acc: 0.9980, val loss: 0.0150, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4380] train loss: 0.0095, train acc: 0.9977, val loss: 0.0136, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4400] train loss: 0.0068, train acc: 0.9986, val loss: 0.0130, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4420] train loss: 0.0073, train acc: 0.9985, val loss: 0.0137, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4440] train loss: 0.0084, train acc: 0.9983, val loss: 0.0132, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0056  @ epoch 4078 )\n",
      "[Epoch: 4460] train loss: 0.0087, train acc: 0.9980, val loss: 0.0128, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0053  @ epoch 4444 )\n",
      "[Epoch: 4480] train loss: 0.0083, train acc: 0.9978, val loss: 0.0140, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9987, best train loss: 0.0053  @ epoch 4444 )\n",
      "[Epoch: 4500] train loss: 0.0070, train acc: 0.9983, val loss: 0.0138, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0053  @ epoch 4444 )\n",
      "[Epoch: 4520] train loss: 0.0076, train acc: 0.9983, val loss: 0.0135, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0053  @ epoch 4444 )\n",
      "[Epoch: 4540] train loss: 0.0066, train acc: 0.9987, val loss: 0.0147, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0053  @ epoch 4444 )\n",
      "[Epoch: 4560] train loss: 0.0081, train acc: 0.9982, val loss: 0.0148, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0053  @ epoch 4444 )\n",
      "[Epoch: 4580] train loss: 0.0064, train acc: 0.9985, val loss: 0.0127, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0053  @ epoch 4444 )\n",
      "[Epoch: 4600] train loss: 0.0070, train acc: 0.9986, val loss: 0.0130, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4620] train loss: 0.0087, train acc: 0.9978, val loss: 0.0132, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4640] train loss: 0.0073, train acc: 0.9984, val loss: 0.0140, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4660] train loss: 0.0071, train acc: 0.9987, val loss: 0.0148, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4680] train loss: 0.0096, train acc: 0.9976, val loss: 0.0133, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4700] train loss: 0.0082, train acc: 0.9978, val loss: 0.0156, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4720] train loss: 0.0073, train acc: 0.9984, val loss: 0.0133, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4740] train loss: 0.0077, train acc: 0.9985, val loss: 0.0131, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4760] train loss: 0.0075, train acc: 0.9983, val loss: 0.0127, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4780] train loss: 0.4746, train acc: 0.9481, val loss: 0.2606, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4800] train loss: 0.2070, train acc: 0.9482, val loss: 0.1548, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4820] train loss: 0.1846, train acc: 0.9482, val loss: 0.1491, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4840] train loss: 0.1854, train acc: 0.9482, val loss: 0.1483, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4860] train loss: 0.1862, train acc: 0.9482, val loss: 0.1484, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4880] train loss: 0.1862, train acc: 0.9482, val loss: 0.1479, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4900] train loss: 0.1841, train acc: 0.9482, val loss: 0.1477, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4920] train loss: 0.1834, train acc: 0.9482, val loss: 0.1479, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4940] train loss: 0.1834, train acc: 0.9482, val loss: 0.1486, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4960] train loss: 0.1816, train acc: 0.9482, val loss: 0.1489, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 4980] train loss: 0.1795, train acc: 0.9482, val loss: 0.1489, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5000] train loss: 0.1814, train acc: 0.9482, val loss: 0.1482, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5020] train loss: 0.1793, train acc: 0.9482, val loss: 0.1475, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5040] train loss: 0.1723, train acc: 0.9482, val loss: 0.1416, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5060] train loss: 0.1615, train acc: 0.9482, val loss: 0.1342, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5080] train loss: 0.1558, train acc: 0.9482, val loss: 0.1218, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5100] train loss: 0.1481, train acc: 0.9482, val loss: 0.1137, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5120] train loss: 0.1461, train acc: 0.9482, val loss: 0.1112, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5140] train loss: 0.1395, train acc: 0.9482, val loss: 0.1088, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5160] train loss: 0.1262, train acc: 0.9464, val loss: 0.1088, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5180] train loss: 0.1025, train acc: 0.9467, val loss: 0.0938, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5200] train loss: 0.0996, train acc: 0.9479, val loss: 0.0917, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5220] train loss: 0.1003, train acc: 0.9477, val loss: 0.0929, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5240] train loss: 0.0989, train acc: 0.9475, val loss: 0.0919, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5260] train loss: 0.0979, train acc: 0.9479, val loss: 0.0897, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5280] train loss: 0.0971, train acc: 0.9478, val loss: 0.0900, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5300] train loss: 0.0986, train acc: 0.9478, val loss: 0.0925, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5320] train loss: 0.0969, train acc: 0.9472, val loss: 0.0898, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5340] train loss: 0.0981, train acc: 0.9479, val loss: 0.0918, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5360] train loss: 0.0981, train acc: 0.9480, val loss: 0.0914, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5380] train loss: 0.0941, train acc: 0.9489, val loss: 0.0904, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5400] train loss: 0.0914, train acc: 0.9524, val loss: 0.0904, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5420] train loss: 0.0929, train acc: 0.9547, val loss: 0.0949, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5440] train loss: 0.0906, train acc: 0.9555, val loss: 0.0934, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5460] train loss: 0.0915, train acc: 0.9551, val loss: 0.0932, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5480] train loss: 0.0913, train acc: 0.9563, val loss: 0.0898, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5500] train loss: 0.0910, train acc: 0.9571, val loss: 0.0898, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5520] train loss: 0.0905, train acc: 0.9580, val loss: 0.0912, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5540] train loss: 0.0907, train acc: 0.9579, val loss: 0.0923, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5560] train loss: 0.0903, train acc: 0.9578, val loss: 0.0927, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5580] train loss: 0.0894, train acc: 0.9581, val loss: 0.0938, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5600] train loss: 0.0883, train acc: 0.9599, val loss: 0.0899, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5620] train loss: 0.0899, train acc: 0.9594, val loss: 0.0916, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5640] train loss: 0.0903, train acc: 0.9580, val loss: 0.0914, val acc: 0.9481  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5660] train loss: 0.0894, train acc: 0.9591, val loss: 0.0919, val acc: 0.9484  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5680] train loss: 0.0881, train acc: 0.9596, val loss: 0.0888, val acc: 0.9484  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5700] train loss: 0.0868, train acc: 0.9606, val loss: 0.0870, val acc: 0.9487  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5720] train loss: 0.0855, train acc: 0.9610, val loss: 0.0879, val acc: 0.9487  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5740] train loss: 0.0858, train acc: 0.9623, val loss: 0.0857, val acc: 0.9491  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5760] train loss: 0.0836, train acc: 0.9609, val loss: 0.0868, val acc: 0.9494  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5780] train loss: 0.0827, train acc: 0.9626, val loss: 0.0823, val acc: 0.9508  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5800] train loss: 0.0856, train acc: 0.9619, val loss: 0.0823, val acc: 0.9511  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5820] train loss: 0.0815, train acc: 0.9638, val loss: 0.0818, val acc: 0.9528  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5840] train loss: 0.0839, train acc: 0.9628, val loss: 0.0807, val acc: 0.9545  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5860] train loss: 0.0825, train acc: 0.9639, val loss: 0.0776, val acc: 0.9595  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5880] train loss: 0.0802, train acc: 0.9644, val loss: 0.0809, val acc: 0.9589  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5900] train loss: 0.0802, train acc: 0.9639, val loss: 0.0808, val acc: 0.9612  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5920] train loss: 0.0767, train acc: 0.9677, val loss: 0.0780, val acc: 0.9636  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5940] train loss: 0.0760, train acc: 0.9666, val loss: 0.0772, val acc: 0.9646  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5960] train loss: 0.0741, train acc: 0.9687, val loss: 0.0731, val acc: 0.9676  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 5980] train loss: 0.0700, train acc: 0.9711, val loss: 0.0692, val acc: 0.9713  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6000] train loss: 0.0657, train acc: 0.9743, val loss: 0.0669, val acc: 0.9727  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6020] train loss: 0.0697, train acc: 0.9719, val loss: 0.0652, val acc: 0.9737  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6040] train loss: 0.0682, train acc: 0.9730, val loss: 0.0658, val acc: 0.9734  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6060] train loss: 0.0675, train acc: 0.9735, val loss: 0.0618, val acc: 0.9747  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6080] train loss: 0.0675, train acc: 0.9730, val loss: 0.0616, val acc: 0.9761  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6100] train loss: 0.0663, train acc: 0.9726, val loss: 0.0646, val acc: 0.9740  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6120] train loss: 0.0654, train acc: 0.9740, val loss: 0.0627, val acc: 0.9754  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6140] train loss: 0.0665, train acc: 0.9735, val loss: 0.0650, val acc: 0.9757  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6160] train loss: 0.0626, train acc: 0.9750, val loss: 0.0573, val acc: 0.9774  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6180] train loss: 0.0652, train acc: 0.9729, val loss: 0.0636, val acc: 0.9761  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6200] train loss: 0.0614, train acc: 0.9746, val loss: 0.0615, val acc: 0.9771  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6220] train loss: 0.0597, train acc: 0.9761, val loss: 0.0550, val acc: 0.9818  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6240] train loss: 0.0597, train acc: 0.9764, val loss: 0.0513, val acc: 0.9841  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6260] train loss: 0.0539, train acc: 0.9790, val loss: 0.0381, val acc: 0.9906  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6280] train loss: 0.0490, train acc: 0.9816, val loss: 0.0278, val acc: 0.9963  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6300] train loss: 0.0438, train acc: 0.9842, val loss: 0.0290, val acc: 0.9953  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6320] train loss: 0.0455, train acc: 0.9829, val loss: 0.0281, val acc: 0.9956  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6340] train loss: 0.0442, train acc: 0.9831, val loss: 0.0258, val acc: 0.9976  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6360] train loss: 0.0429, train acc: 0.9840, val loss: 0.0255, val acc: 0.9966  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6380] train loss: 0.0411, train acc: 0.9838, val loss: 0.0256, val acc: 0.9970  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6400] train loss: 0.0422, train acc: 0.9847, val loss: 0.0265, val acc: 0.9963  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6420] train loss: 0.0426, train acc: 0.9837, val loss: 0.0243, val acc: 0.9976  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6440] train loss: 0.0410, train acc: 0.9858, val loss: 0.0244, val acc: 0.9976  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6460] train loss: 0.0392, train acc: 0.9863, val loss: 0.0241, val acc: 0.9976  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6480] train loss: 0.0427, train acc: 0.9845, val loss: 0.0249, val acc: 0.9973  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6500] train loss: 0.0415, train acc: 0.9846, val loss: 0.0228, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6520] train loss: 0.0402, train acc: 0.9854, val loss: 0.0234, val acc: 0.9973  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6540] train loss: 0.0397, train acc: 0.9858, val loss: 0.0237, val acc: 0.9976  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6560] train loss: 0.0411, train acc: 0.9857, val loss: 0.0239, val acc: 0.9976  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6580] train loss: 0.0387, train acc: 0.9855, val loss: 0.0222, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6600] train loss: 0.0409, train acc: 0.9840, val loss: 0.0228, val acc: 0.9976  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6620] train loss: 0.0404, train acc: 0.9853, val loss: 0.0216, val acc: 0.9976  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6640] train loss: 0.0364, train acc: 0.9871, val loss: 0.0211, val acc: 0.9976  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6660] train loss: 0.0324, train acc: 0.9882, val loss: 0.0218, val acc: 0.9973  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6680] train loss: 0.0290, train acc: 0.9903, val loss: 0.0207, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6700] train loss: 0.0287, train acc: 0.9902, val loss: 0.0199, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6720] train loss: 0.0298, train acc: 0.9900, val loss: 0.0201, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6740] train loss: 0.0254, train acc: 0.9918, val loss: 0.0202, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6760] train loss: 0.0299, train acc: 0.9900, val loss: 0.0202, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6780] train loss: 0.0275, train acc: 0.9913, val loss: 0.0196, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6800] train loss: 0.0247, train acc: 0.9918, val loss: 0.0199, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6820] train loss: 0.0253, train acc: 0.9913, val loss: 0.0193, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6840] train loss: 0.0255, train acc: 0.9913, val loss: 0.0194, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6860] train loss: 0.0259, train acc: 0.9919, val loss: 0.0193, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6880] train loss: 0.0245, train acc: 0.9913, val loss: 0.0192, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6900] train loss: 0.0254, train acc: 0.9912, val loss: 0.0194, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6920] train loss: 0.0224, train acc: 0.9926, val loss: 0.0191, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6940] train loss: 0.0259, train acc: 0.9916, val loss: 0.0202, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6960] train loss: 0.0244, train acc: 0.9928, val loss: 0.0199, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 6980] train loss: 0.0279, train acc: 0.9913, val loss: 0.0193, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7000] train loss: 0.0232, train acc: 0.9921, val loss: 0.0199, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7020] train loss: 0.0226, train acc: 0.9936, val loss: 0.0186, val acc: 0.9976  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7040] train loss: 0.0204, train acc: 0.9941, val loss: 0.0188, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7060] train loss: 0.0166, train acc: 0.9951, val loss: 0.0192, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7080] train loss: 0.0163, train acc: 0.9951, val loss: 0.0203, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7100] train loss: 0.0187, train acc: 0.9941, val loss: 0.0198, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7120] train loss: 0.0188, train acc: 0.9949, val loss: 0.0215, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7140] train loss: 0.0185, train acc: 0.9944, val loss: 0.0194, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7160] train loss: 0.0182, train acc: 0.9945, val loss: 0.0194, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7180] train loss: 0.0178, train acc: 0.9945, val loss: 0.0189, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7200] train loss: 0.0189, train acc: 0.9943, val loss: 0.0196, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7220] train loss: 0.0156, train acc: 0.9950, val loss: 0.0199, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7240] train loss: 0.0161, train acc: 0.9952, val loss: 0.0197, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7260] train loss: 0.0168, train acc: 0.9949, val loss: 0.0184, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7280] train loss: 0.0184, train acc: 0.9944, val loss: 0.0188, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7300] train loss: 0.0169, train acc: 0.9956, val loss: 0.0191, val acc: 0.9980  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7320] train loss: 0.0190, train acc: 0.9944, val loss: 0.0183, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7340] train loss: 0.0180, train acc: 0.9949, val loss: 0.0197, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7360] train loss: 0.0180, train acc: 0.9945, val loss: 0.0183, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7380] train loss: 0.0157, train acc: 0.9951, val loss: 0.0180, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7400] train loss: 0.0167, train acc: 0.9951, val loss: 0.0177, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7420] train loss: 0.0157, train acc: 0.9954, val loss: 0.0185, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7440] train loss: 0.0167, train acc: 0.9953, val loss: 0.0176, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7460] train loss: 0.0163, train acc: 0.9949, val loss: 0.0179, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7480] train loss: 0.0151, train acc: 0.9955, val loss: 0.0187, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7500] train loss: 0.0174, train acc: 0.9956, val loss: 0.0174, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7520] train loss: 0.0162, train acc: 0.9954, val loss: 0.0182, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7540] train loss: 0.0161, train acc: 0.9947, val loss: 0.0179, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7560] train loss: 0.0152, train acc: 0.9952, val loss: 0.0178, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7580] train loss: 0.0161, train acc: 0.9953, val loss: 0.0176, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7600] train loss: 0.0155, train acc: 0.9954, val loss: 0.0166, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7620] train loss: 0.0177, train acc: 0.9948, val loss: 0.0178, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7640] train loss: 0.0176, train acc: 0.9950, val loss: 0.0177, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7660] train loss: 0.0159, train acc: 0.9958, val loss: 0.0175, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7680] train loss: 0.0164, train acc: 0.9950, val loss: 0.0161, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7700] train loss: 0.0142, train acc: 0.9963, val loss: 0.0168, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7720] train loss: 0.0134, train acc: 0.9960, val loss: 0.0178, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7740] train loss: 0.0174, train acc: 0.9949, val loss: 0.0168, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7760] train loss: 0.0142, train acc: 0.9960, val loss: 0.0159, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7780] train loss: 0.0151, train acc: 0.9960, val loss: 0.0163, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7800] train loss: 0.0177, train acc: 0.9947, val loss: 0.0164, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7820] train loss: 0.0159, train acc: 0.9949, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7840] train loss: 0.0142, train acc: 0.9960, val loss: 0.0161, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7860] train loss: 0.0171, train acc: 0.9952, val loss: 0.0161, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7880] train loss: 0.0168, train acc: 0.9952, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7900] train loss: 0.0138, train acc: 0.9960, val loss: 0.0164, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7920] train loss: 0.0172, train acc: 0.9949, val loss: 0.0168, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7940] train loss: 0.0163, train acc: 0.9952, val loss: 0.0176, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7960] train loss: 0.0157, train acc: 0.9956, val loss: 0.0164, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 7980] train loss: 0.0139, train acc: 0.9960, val loss: 0.0164, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8000] train loss: 0.0162, train acc: 0.9949, val loss: 0.0155, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8020] train loss: 0.0149, train acc: 0.9954, val loss: 0.0162, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8040] train loss: 0.0187, train acc: 0.9946, val loss: 0.0154, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8060] train loss: 0.0154, train acc: 0.9954, val loss: 0.0158, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8080] train loss: 0.0148, train acc: 0.9953, val loss: 0.0161, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8100] train loss: 0.0145, train acc: 0.9961, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8120] train loss: 0.0163, train acc: 0.9951, val loss: 0.0165, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8140] train loss: 0.0173, train acc: 0.9952, val loss: 0.0156, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8160] train loss: 0.0151, train acc: 0.9952, val loss: 0.0156, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8180] train loss: 0.0154, train acc: 0.9956, val loss: 0.0161, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8200] train loss: 0.0146, train acc: 0.9956, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8220] train loss: 0.0169, train acc: 0.9949, val loss: 0.0161, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8240] train loss: 0.0138, train acc: 0.9959, val loss: 0.0163, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8260] train loss: 0.0185, train acc: 0.9944, val loss: 0.0155, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8280] train loss: 0.0163, train acc: 0.9954, val loss: 0.0162, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8300] train loss: 0.0148, train acc: 0.9957, val loss: 0.0159, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8320] train loss: 0.0166, train acc: 0.9952, val loss: 0.0160, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8340] train loss: 0.0142, train acc: 0.9958, val loss: 0.0166, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8360] train loss: 0.0142, train acc: 0.9959, val loss: 0.0159, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8380] train loss: 0.0132, train acc: 0.9961, val loss: 0.0158, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8400] train loss: 0.0149, train acc: 0.9951, val loss: 0.0162, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8420] train loss: 0.0154, train acc: 0.9957, val loss: 0.0157, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8440] train loss: 0.0139, train acc: 0.9956, val loss: 0.0160, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8460] train loss: 0.0139, train acc: 0.9961, val loss: 0.0161, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8480] train loss: 0.0144, train acc: 0.9954, val loss: 0.0154, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8500] train loss: 0.0146, train acc: 0.9952, val loss: 0.0166, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8520] train loss: 0.0127, train acc: 0.9967, val loss: 0.0162, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8540] train loss: 0.0119, train acc: 0.9968, val loss: 0.0156, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8560] train loss: 0.0172, train acc: 0.9944, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8580] train loss: 0.0153, train acc: 0.9952, val loss: 0.0154, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8600] train loss: 0.0183, train acc: 0.9946, val loss: 0.0159, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8620] train loss: 0.0137, train acc: 0.9959, val loss: 0.0163, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8640] train loss: 0.0125, train acc: 0.9964, val loss: 0.0169, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8660] train loss: 0.0148, train acc: 0.9954, val loss: 0.0163, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8680] train loss: 0.0157, train acc: 0.9951, val loss: 0.0165, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8700] train loss: 0.0149, train acc: 0.9953, val loss: 0.0155, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8720] train loss: 0.0155, train acc: 0.9948, val loss: 0.0161, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8740] train loss: 0.0150, train acc: 0.9954, val loss: 0.0165, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8760] train loss: 0.0123, train acc: 0.9963, val loss: 0.0164, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8780] train loss: 0.0112, train acc: 0.9972, val loss: 0.0164, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8800] train loss: 0.0160, train acc: 0.9947, val loss: 0.0166, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8820] train loss: 0.0154, train acc: 0.9953, val loss: 0.0166, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8840] train loss: 0.0155, train acc: 0.9957, val loss: 0.0173, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8860] train loss: 0.0148, train acc: 0.9952, val loss: 0.0165, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8880] train loss: 0.0131, train acc: 0.9961, val loss: 0.0164, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8900] train loss: 0.0159, train acc: 0.9948, val loss: 0.0162, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8920] train loss: 0.0134, train acc: 0.9961, val loss: 0.0163, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8940] train loss: 0.0166, train acc: 0.9953, val loss: 0.0178, val acc: 0.9983  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8960] train loss: 0.0150, train acc: 0.9956, val loss: 0.0171, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 8980] train loss: 0.0141, train acc: 0.9957, val loss: 0.0172, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9000] train loss: 0.0150, train acc: 0.9955, val loss: 0.0166, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9020] train loss: 0.0151, train acc: 0.9959, val loss: 0.0163, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9040] train loss: 0.0169, train acc: 0.9949, val loss: 0.0158, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9060] train loss: 0.0154, train acc: 0.9948, val loss: 0.0160, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9080] train loss: 0.0156, train acc: 0.9952, val loss: 0.0163, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9100] train loss: 0.0169, train acc: 0.9950, val loss: 0.0162, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9120] train loss: 0.0168, train acc: 0.9941, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9140] train loss: 0.0114, train acc: 0.9962, val loss: 0.0160, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9160] train loss: 0.0161, train acc: 0.9947, val loss: 0.0159, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9180] train loss: 0.0208, train acc: 0.9937, val loss: 0.0162, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9200] train loss: 0.0133, train acc: 0.9962, val loss: 0.0165, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9220] train loss: 0.0146, train acc: 0.9954, val loss: 0.0162, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9240] train loss: 0.0132, train acc: 0.9960, val loss: 0.0159, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9260] train loss: 0.0163, train acc: 0.9949, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9280] train loss: 0.0096, train acc: 0.9974, val loss: 0.0174, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9300] train loss: 0.0106, train acc: 0.9975, val loss: 0.0159, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9320] train loss: 0.0088, train acc: 0.9978, val loss: 0.0158, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9340] train loss: 0.0086, train acc: 0.9978, val loss: 0.0160, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9360] train loss: 0.0102, train acc: 0.9972, val loss: 0.0156, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9380] train loss: 0.0089, train acc: 0.9979, val loss: 0.0166, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9400] train loss: 0.0099, train acc: 0.9970, val loss: 0.0163, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9420] train loss: 0.0098, train acc: 0.9977, val loss: 0.0166, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9440] train loss: 0.0098, train acc: 0.9977, val loss: 0.0165, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9460] train loss: 0.0113, train acc: 0.9969, val loss: 0.0160, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9480] train loss: 0.0109, train acc: 0.9970, val loss: 0.0166, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9500] train loss: 0.0095, train acc: 0.9973, val loss: 0.0163, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9520] train loss: 0.0088, train acc: 0.9973, val loss: 0.0168, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9540] train loss: 0.0059, train acc: 0.9986, val loss: 0.0164, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9560] train loss: 0.0085, train acc: 0.9977, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9580] train loss: 0.0095, train acc: 0.9973, val loss: 0.0160, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9600] train loss: 0.0093, train acc: 0.9975, val loss: 0.0159, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9620] train loss: 0.0088, train acc: 0.9980, val loss: 0.0164, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9640] train loss: 0.0070, train acc: 0.9980, val loss: 0.0167, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9660] train loss: 0.0085, train acc: 0.9975, val loss: 0.0165, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9680] train loss: 0.0084, train acc: 0.9978, val loss: 0.0154, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9700] train loss: 0.0082, train acc: 0.9980, val loss: 0.0159, val acc: 0.9990  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9720] train loss: 0.0071, train acc: 0.9983, val loss: 0.0166, val acc: 0.9987  (best train acc: 0.9991, best val acc: 0.9990, best train loss: 0.0052  @ epoch 4596 )\n",
      "[Epoch: 9740] train loss: 0.0073, train acc: 0.9983, val loss: 0.0168, val acc: 0.9987  (best train acc: 0.9992, best val acc: 0.9990, best train loss: 0.0046  @ epoch 9721 )\n",
      "[Epoch: 9760] train loss: 0.0052, train acc: 0.9990, val loss: 0.0168, val acc: 0.9987  (best train acc: 0.9992, best val acc: 0.9990, best train loss: 0.0046  @ epoch 9721 )\n",
      "[Epoch: 9780] train loss: 0.0051, train acc: 0.9988, val loss: 0.0166, val acc: 0.9987  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0044  @ epoch 9766 )\n",
      "[Epoch: 9800] train loss: 0.0069, train acc: 0.9981, val loss: 0.0158, val acc: 0.9990  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0044  @ epoch 9766 )\n",
      "[Epoch: 9820] train loss: 0.0055, train acc: 0.9987, val loss: 0.0167, val acc: 0.9987  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0044  @ epoch 9811 )\n",
      "[Epoch: 9840] train loss: 0.0082, train acc: 0.9978, val loss: 0.0172, val acc: 0.9987  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0044  @ epoch 9811 )\n",
      "[Epoch: 9860] train loss: 0.0070, train acc: 0.9986, val loss: 0.0169, val acc: 0.9983  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0044  @ epoch 9811 )\n",
      "[Epoch: 9880] train loss: 0.0060, train acc: 0.9986, val loss: 0.0168, val acc: 0.9983  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0044  @ epoch 9811 )\n",
      "[Epoch: 9900] train loss: 0.0079, train acc: 0.9981, val loss: 0.0160, val acc: 0.9987  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0044  @ epoch 9811 )\n",
      "[Epoch: 9920] train loss: 0.0041, train acc: 0.9992, val loss: 0.0174, val acc: 0.9987  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 9940] train loss: 0.0043, train acc: 0.9993, val loss: 0.0170, val acc: 0.9987  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 9960] train loss: 0.0053, train acc: 0.9990, val loss: 0.0176, val acc: 0.9983  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 9980] train loss: 0.0052, train acc: 0.9988, val loss: 0.0167, val acc: 0.9990  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10000] train loss: 0.0060, train acc: 0.9987, val loss: 0.0160, val acc: 0.9990  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10020] train loss: 0.0047, train acc: 0.9991, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10040] train loss: 0.0063, train acc: 0.9988, val loss: 0.0160, val acc: 0.9987  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10060] train loss: 0.0061, train acc: 0.9984, val loss: 0.0168, val acc: 0.9987  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10080] train loss: 0.0060, train acc: 0.9989, val loss: 0.0161, val acc: 0.9990  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10100] train loss: 0.0069, train acc: 0.9984, val loss: 0.0168, val acc: 0.9987  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10120] train loss: 0.0055, train acc: 0.9990, val loss: 0.0170, val acc: 0.9990  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10140] train loss: 0.0070, train acc: 0.9984, val loss: 0.0155, val acc: 0.9987  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10160] train loss: 0.0067, train acc: 0.9983, val loss: 0.0161, val acc: 0.9990  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10180] train loss: 0.0073, train acc: 0.9982, val loss: 0.0160, val acc: 0.9987  (best train acc: 0.9993, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10200] train loss: 0.0051, train acc: 0.9991, val loss: 0.0158, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0041  @ epoch 9920 )\n",
      "[Epoch: 10220] train loss: 0.0070, train acc: 0.9988, val loss: 0.0156, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0040  @ epoch 10204 )\n",
      "[Epoch: 10240] train loss: 0.0072, train acc: 0.9980, val loss: 0.0154, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0040  @ epoch 10204 )\n",
      "[Epoch: 10260] train loss: 0.0052, train acc: 0.9988, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0040  @ epoch 10204 )\n",
      "[Epoch: 10280] train loss: 0.0066, train acc: 0.9987, val loss: 0.0155, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0040  @ epoch 10204 )\n",
      "[Epoch: 10300] train loss: 0.0070, train acc: 0.9984, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0040  @ epoch 10204 )\n",
      "[Epoch: 10320] train loss: 0.0044, train acc: 0.9991, val loss: 0.0164, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0040  @ epoch 10204 )\n",
      "[Epoch: 10340] train loss: 0.0099, train acc: 0.9976, val loss: 0.0166, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0040  @ epoch 10204 )\n",
      "[Epoch: 10360] train loss: 0.0066, train acc: 0.9985, val loss: 0.0158, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0040  @ epoch 10204 )\n",
      "[Epoch: 10380] train loss: 0.0049, train acc: 0.9991, val loss: 0.0167, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0040  @ epoch 10204 )\n",
      "[Epoch: 10400] train loss: 0.0072, train acc: 0.9983, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10420] train loss: 0.0060, train acc: 0.9986, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10440] train loss: 0.0048, train acc: 0.9989, val loss: 0.0165, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10460] train loss: 0.0066, train acc: 0.9987, val loss: 0.0154, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10480] train loss: 0.0048, train acc: 0.9988, val loss: 0.0171, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10500] train loss: 0.0046, train acc: 0.9993, val loss: 0.0163, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10520] train loss: 0.0064, train acc: 0.9988, val loss: 0.0158, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10540] train loss: 0.0040, train acc: 0.9993, val loss: 0.0163, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10560] train loss: 0.0071, train acc: 0.9985, val loss: 0.0159, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10580] train loss: 0.0051, train acc: 0.9988, val loss: 0.0161, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10600] train loss: 0.0056, train acc: 0.9985, val loss: 0.0170, val acc: 0.9983  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10620] train loss: 0.0043, train acc: 0.9990, val loss: 0.0170, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10640] train loss: 0.0062, train acc: 0.9986, val loss: 0.0167, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10660] train loss: 0.0070, train acc: 0.9988, val loss: 0.0163, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10680] train loss: 0.0064, train acc: 0.9985, val loss: 0.0154, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10700] train loss: 0.0055, train acc: 0.9987, val loss: 0.0160, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10720] train loss: 0.0068, train acc: 0.9983, val loss: 0.0172, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10740] train loss: 0.0066, train acc: 0.9985, val loss: 0.0164, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10760] train loss: 0.0071, train acc: 0.9983, val loss: 0.0162, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0039  @ epoch 10383 )\n",
      "[Epoch: 10780] train loss: 0.0062, train acc: 0.9986, val loss: 0.0156, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0038  @ epoch 10769 )\n",
      "[Epoch: 10800] train loss: 0.0054, train acc: 0.9992, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0038  @ epoch 10769 )\n",
      "[Epoch: 10820] train loss: 0.0051, train acc: 0.9990, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 10840] train loss: 0.0056, train acc: 0.9987, val loss: 0.0158, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 10860] train loss: 0.0059, train acc: 0.9986, val loss: 0.0158, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 10880] train loss: 0.0054, train acc: 0.9989, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 10900] train loss: 0.0065, train acc: 0.9983, val loss: 0.0156, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 10920] train loss: 0.0067, train acc: 0.9986, val loss: 0.0153, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 10940] train loss: 0.0050, train acc: 0.9993, val loss: 0.0146, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 10960] train loss: 0.0064, train acc: 0.9986, val loss: 0.0157, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 10980] train loss: 0.0054, train acc: 0.9991, val loss: 0.0156, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11000] train loss: 0.0056, train acc: 0.9987, val loss: 0.0147, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11020] train loss: 0.0060, train acc: 0.9981, val loss: 0.0139, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11040] train loss: 0.0060, train acc: 0.9981, val loss: 0.0145, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11060] train loss: 0.0036, train acc: 0.9991, val loss: 0.0148, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11080] train loss: 0.0040, train acc: 0.9991, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11100] train loss: 0.0037, train acc: 0.9993, val loss: 0.0154, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11120] train loss: 0.0047, train acc: 0.9988, val loss: 0.0160, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11140] train loss: 0.0057, train acc: 0.9983, val loss: 0.0149, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11160] train loss: 0.0058, train acc: 0.9986, val loss: 0.0145, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11180] train loss: 0.0061, train acc: 0.9984, val loss: 0.0157, val acc: 0.9983  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11200] train loss: 0.0054, train acc: 0.9983, val loss: 0.0146, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11220] train loss: 0.0055, train acc: 0.9986, val loss: 0.0145, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11240] train loss: 0.0079, train acc: 0.9980, val loss: 0.0147, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11260] train loss: 0.0055, train acc: 0.9988, val loss: 0.0145, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11280] train loss: 0.0055, train acc: 0.9987, val loss: 0.0143, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11300] train loss: 0.0046, train acc: 0.9986, val loss: 0.0147, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11320] train loss: 0.0047, train acc: 0.9989, val loss: 0.0153, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11340] train loss: 0.0054, train acc: 0.9986, val loss: 0.0150, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11360] train loss: 0.0058, train acc: 0.9987, val loss: 0.0153, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11380] train loss: 0.0059, train acc: 0.9984, val loss: 0.0148, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0032  @ epoch 10809 )\n",
      "[Epoch: 11400] train loss: 0.0048, train acc: 0.9989, val loss: 0.0141, val acc: 0.9990  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0031  @ epoch 11381 )\n",
      "[Epoch: 11420] train loss: 0.0048, train acc: 0.9988, val loss: 0.0151, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0031  @ epoch 11381 )\n",
      "[Epoch: 11440] train loss: 0.0052, train acc: 0.9986, val loss: 0.0152, val acc: 0.9987  (best train acc: 0.9994, best val acc: 0.9990, best train loss: 0.0031  @ epoch 11381 )\n",
      "[Epoch: 11460] train loss: 0.0058, train acc: 0.9981, val loss: 0.0145, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0030  @ epoch 11454 )\n",
      "[Epoch: 11480] train loss: 0.0053, train acc: 0.9988, val loss: 0.0149, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0028  @ epoch 11468 )\n",
      "[Epoch: 11500] train loss: 0.0051, train acc: 0.9991, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11520] train loss: 0.0044, train acc: 0.9991, val loss: 0.0149, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11540] train loss: 0.0055, train acc: 0.9980, val loss: 0.0151, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11560] train loss: 0.0050, train acc: 0.9987, val loss: 0.0144, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11580] train loss: 0.0053, train acc: 0.9986, val loss: 0.0148, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11600] train loss: 0.0062, train acc: 0.9984, val loss: 0.0158, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11620] train loss: 0.0060, train acc: 0.9983, val loss: 0.0148, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11640] train loss: 0.0064, train acc: 0.9983, val loss: 0.0152, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11660] train loss: 0.0055, train acc: 0.9988, val loss: 0.0153, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11680] train loss: 0.0059, train acc: 0.9985, val loss: 0.0142, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11700] train loss: 0.0047, train acc: 0.9989, val loss: 0.0144, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11720] train loss: 0.0042, train acc: 0.9993, val loss: 0.0153, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11740] train loss: 0.0048, train acc: 0.9987, val loss: 0.0149, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11760] train loss: 0.0051, train acc: 0.9988, val loss: 0.0142, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11780] train loss: 0.0069, train acc: 0.9983, val loss: 0.0167, val acc: 0.9980  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11800] train loss: 0.0054, train acc: 0.9985, val loss: 0.0157, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11820] train loss: 0.0058, train acc: 0.9986, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11840] train loss: 0.0070, train acc: 0.9983, val loss: 0.0144, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11860] train loss: 0.0051, train acc: 0.9986, val loss: 0.0152, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11880] train loss: 0.0051, train acc: 0.9985, val loss: 0.0156, val acc: 0.9983  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11900] train loss: 0.0045, train acc: 0.9989, val loss: 0.0150, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11920] train loss: 0.0071, train acc: 0.9983, val loss: 0.0156, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11940] train loss: 0.0050, train acc: 0.9986, val loss: 0.0147, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11960] train loss: 0.0076, train acc: 0.9979, val loss: 0.0146, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 11980] train loss: 0.0048, train acc: 0.9990, val loss: 0.0145, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12000] train loss: 0.0037, train acc: 0.9991, val loss: 0.0161, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12020] train loss: 0.0052, train acc: 0.9987, val loss: 0.0150, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12040] train loss: 0.0053, train acc: 0.9988, val loss: 0.0145, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12060] train loss: 0.0043, train acc: 0.9989, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12080] train loss: 0.0041, train acc: 0.9993, val loss: 0.0148, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12100] train loss: 0.0054, train acc: 0.9987, val loss: 0.0153, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12120] train loss: 0.0070, train acc: 0.9985, val loss: 0.0142, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12140] train loss: 0.0049, train acc: 0.9988, val loss: 0.0138, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12160] train loss: 0.0061, train acc: 0.9985, val loss: 0.0150, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12180] train loss: 0.0039, train acc: 0.9992, val loss: 0.0152, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12200] train loss: 0.0063, train acc: 0.9985, val loss: 0.0147, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12220] train loss: 0.0048, train acc: 0.9987, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12240] train loss: 0.0038, train acc: 0.9991, val loss: 0.0145, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12260] train loss: 0.0051, train acc: 0.9988, val loss: 0.0148, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12280] train loss: 0.0064, train acc: 0.9986, val loss: 0.0145, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12300] train loss: 0.0041, train acc: 0.9990, val loss: 0.0144, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12320] train loss: 0.0045, train acc: 0.9991, val loss: 0.0143, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12340] train loss: 0.0060, train acc: 0.9983, val loss: 0.0142, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12360] train loss: 0.0050, train acc: 0.9988, val loss: 0.0142, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12380] train loss: 0.0048, train acc: 0.9989, val loss: 0.0140, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12400] train loss: 0.0044, train acc: 0.9987, val loss: 0.0146, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12420] train loss: 0.0070, train acc: 0.9982, val loss: 0.0143, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12440] train loss: 0.0062, train acc: 0.9982, val loss: 0.0148, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12460] train loss: 0.0038, train acc: 0.9991, val loss: 0.0150, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12480] train loss: 0.0043, train acc: 0.9989, val loss: 0.0140, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12500] train loss: 0.0046, train acc: 0.9988, val loss: 0.0149, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12520] train loss: 0.0060, train acc: 0.9984, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12540] train loss: 0.0058, train acc: 0.9986, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12560] train loss: 0.0061, train acc: 0.9985, val loss: 0.0153, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12580] train loss: 0.0040, train acc: 0.9993, val loss: 0.0148, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12600] train loss: 0.0040, train acc: 0.9991, val loss: 0.0144, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12620] train loss: 0.0060, train acc: 0.9985, val loss: 0.0143, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12640] train loss: 0.0052, train acc: 0.9988, val loss: 0.0145, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12660] train loss: 0.0047, train acc: 0.9991, val loss: 0.0153, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12680] train loss: 0.0046, train acc: 0.9991, val loss: 0.0154, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12700] train loss: 0.0041, train acc: 0.9990, val loss: 0.0149, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12720] train loss: 0.0056, train acc: 0.9984, val loss: 0.0145, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12740] train loss: 0.0059, train acc: 0.9986, val loss: 0.0140, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12760] train loss: 0.0044, train acc: 0.9991, val loss: 0.0149, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12780] train loss: 0.0052, train acc: 0.9985, val loss: 0.0136, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12800] train loss: 0.0051, train acc: 0.9990, val loss: 0.0140, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12820] train loss: 0.0062, train acc: 0.9987, val loss: 0.0132, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12840] train loss: 0.0055, train acc: 0.9986, val loss: 0.0139, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12860] train loss: 0.0044, train acc: 0.9991, val loss: 0.0141, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12880] train loss: 0.0071, train acc: 0.9986, val loss: 0.0154, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12900] train loss: 0.0055, train acc: 0.9991, val loss: 0.0149, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12920] train loss: 0.0050, train acc: 0.9988, val loss: 0.0142, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12940] train loss: 0.0048, train acc: 0.9991, val loss: 0.0155, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12960] train loss: 0.0058, train acc: 0.9986, val loss: 0.0157, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 12980] train loss: 0.0042, train acc: 0.9988, val loss: 0.0153, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 13000] train loss: 0.0058, train acc: 0.9983, val loss: 0.0150, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 13020] train loss: 0.0047, train acc: 0.9986, val loss: 0.0154, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 13040] train loss: 0.0053, train acc: 0.9988, val loss: 0.0146, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 13060] train loss: 0.0056, train acc: 0.9985, val loss: 0.0141, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 13080] train loss: 0.0062, train acc: 0.9986, val loss: 0.0135, val acc: 0.9983  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 13100] train loss: 0.0042, train acc: 0.9992, val loss: 0.0134, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0023  @ epoch 11496 )\n",
      "[Epoch: 13120] train loss: 0.0032, train acc: 0.9993, val loss: 0.0140, val acc: 0.9990  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0022  @ epoch 13102 )\n",
      "[Epoch: 13140] train loss: 0.0035, train acc: 0.9993, val loss: 0.0143, val acc: 0.9987  (best train acc: 0.9996, best val acc: 0.9990, best train loss: 0.0022  @ epoch 13102 )\n",
      "[Epoch: 13160] train loss: 0.0026, train acc: 0.9996, val loss: 0.0134, val acc: 0.9990  (best train acc: 0.9997, best val acc: 0.9990, best train loss: 0.0021  @ epoch 13156 )\n",
      "[Epoch: 13180] train loss: 0.0034, train acc: 0.9994, val loss: 0.0142, val acc: 0.9987  (best train acc: 0.9997, best val acc: 0.9990, best train loss: 0.0020  @ epoch 13166 )\n",
      "[Epoch: 13200] train loss: 0.0046, train acc: 0.9990, val loss: 0.0140, val acc: 0.9990  (best train acc: 0.9997, best val acc: 0.9990, best train loss: 0.0017  @ epoch 13198 )\n",
      "[Epoch: 13220] train loss: 0.0040, train acc: 0.9992, val loss: 0.0146, val acc: 0.9987  (best train acc: 0.9997, best val acc: 0.9990, best train loss: 0.0017  @ epoch 13198 )\n",
      "[Epoch: 13240] train loss: 0.0041, train acc: 0.9992, val loss: 0.0148, val acc: 0.9987  (best train acc: 0.9997, best val acc: 0.9990, best train loss: 0.0017  @ epoch 13198 )\n",
      "[Epoch: 13260] train loss: 0.0029, train acc: 0.9992, val loss: 0.0135, val acc: 0.9990  (best train acc: 0.9997, best val acc: 0.9990, best train loss: 0.0017  @ epoch 13198 )\n",
      "[Epoch: 13280] train loss: 0.0033, train acc: 0.9994, val loss: 0.0145, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9990, best train loss: 0.0017  @ epoch 13198 )\n",
      "[Epoch: 13300] train loss: 0.0041, train acc: 0.9991, val loss: 0.0141, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9990, best train loss: 0.0017  @ epoch 13198 )\n",
      "[Epoch: 13320] train loss: 0.0036, train acc: 0.9991, val loss: 0.0133, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9990, best train loss: 0.0017  @ epoch 13198 )\n",
      "[Epoch: 13340] train loss: 0.0043, train acc: 0.9990, val loss: 0.0139, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9990, best train loss: 0.0017  @ epoch 13198 )\n",
      "[Epoch: 13360] train loss: 0.0031, train acc: 0.9993, val loss: 0.0143, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9990, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13380] train loss: 0.0031, train acc: 0.9993, val loss: 0.0133, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9990, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13400] train loss: 0.0045, train acc: 0.9992, val loss: 0.0142, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9990, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13420] train loss: 0.0029, train acc: 0.9995, val loss: 0.0133, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9990, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13440] train loss: 0.0043, train acc: 0.9991, val loss: 0.0133, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9990, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13460] train loss: 0.0045, train acc: 0.9989, val loss: 0.0121, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9990, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13480] train loss: 0.0030, train acc: 0.9994, val loss: 0.0139, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9990, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13500] train loss: 0.0032, train acc: 0.9992, val loss: 0.0115, val acc: 0.9993  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13520] train loss: 0.0030, train acc: 0.9996, val loss: 0.0135, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13540] train loss: 0.0025, train acc: 0.9996, val loss: 0.0141, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13560] train loss: 0.0033, train acc: 0.9993, val loss: 0.0154, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13580] train loss: 0.0037, train acc: 0.9991, val loss: 0.0134, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13600] train loss: 0.0061, train acc: 0.9988, val loss: 0.0136, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13620] train loss: 0.0042, train acc: 0.9991, val loss: 0.0143, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13640] train loss: 0.0051, train acc: 0.9988, val loss: 0.0146, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13660] train loss: 0.0034, train acc: 0.9993, val loss: 0.0133, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13680] train loss: 0.0034, train acc: 0.9992, val loss: 0.0141, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13700] train loss: 0.0021, train acc: 0.9999, val loss: 0.0154, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13720] train loss: 0.0042, train acc: 0.9991, val loss: 0.0147, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13740] train loss: 0.0033, train acc: 0.9995, val loss: 0.0147, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13760] train loss: 0.0027, train acc: 0.9995, val loss: 0.0148, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13780] train loss: 0.0042, train acc: 0.9993, val loss: 0.0138, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13800] train loss: 0.0049, train acc: 0.9990, val loss: 0.0141, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13820] train loss: 0.0052, train acc: 0.9993, val loss: 0.0141, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13840] train loss: 0.0030, train acc: 0.9991, val loss: 0.0156, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13860] train loss: 0.0027, train acc: 0.9996, val loss: 0.0133, val acc: 0.9983  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13880] train loss: 0.0123, train acc: 0.9975, val loss: 0.0162, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13900] train loss: 0.0119, train acc: 0.9973, val loss: 0.0042, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13920] train loss: 0.0059, train acc: 0.9989, val loss: 0.0096, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13940] train loss: 0.0039, train acc: 0.9991, val loss: 0.0105, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13960] train loss: 0.0035, train acc: 0.9993, val loss: 0.0105, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 13980] train loss: 0.0037, train acc: 0.9991, val loss: 0.0127, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 14000] train loss: 0.0036, train acc: 0.9992, val loss: 0.0123, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 14020] train loss: 0.0036, train acc: 0.9992, val loss: 0.0138, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 14040] train loss: 0.0035, train acc: 0.9993, val loss: 0.0152, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 14060] train loss: 0.0038, train acc: 0.9994, val loss: 0.0138, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 14080] train loss: 0.0033, train acc: 0.9993, val loss: 0.0130, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 14100] train loss: 0.0046, train acc: 0.9991, val loss: 0.0134, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 14120] train loss: 0.0033, train acc: 0.9995, val loss: 0.0133, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 14140] train loss: 0.0030, train acc: 0.9993, val loss: 0.0132, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 14160] train loss: 0.0037, train acc: 0.9992, val loss: 0.0136, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0015  @ epoch 13346 )\n",
      "[Epoch: 14180] train loss: 0.0040, train acc: 0.9991, val loss: 0.0139, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14200] train loss: 0.0028, train acc: 0.9995, val loss: 0.0124, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14220] train loss: 0.0040, train acc: 0.9991, val loss: 0.0120, val acc: 0.9993  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14240] train loss: 0.0029, train acc: 0.9996, val loss: 0.0133, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14260] train loss: 0.0034, train acc: 0.9994, val loss: 0.0151, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14280] train loss: 0.0038, train acc: 0.9991, val loss: 0.0128, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14300] train loss: 0.0038, train acc: 0.9991, val loss: 0.0131, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14320] train loss: 0.0050, train acc: 0.9988, val loss: 0.0129, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14340] train loss: 0.0039, train acc: 0.9990, val loss: 0.0146, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14360] train loss: 0.0028, train acc: 0.9996, val loss: 0.0129, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14380] train loss: 0.0019, train acc: 0.9995, val loss: 0.0145, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14400] train loss: 0.0036, train acc: 0.9994, val loss: 0.0124, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14420] train loss: 0.0030, train acc: 0.9994, val loss: 0.0134, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14440] train loss: 0.0041, train acc: 0.9993, val loss: 0.0127, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14460] train loss: 0.0037, train acc: 0.9993, val loss: 0.0141, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14480] train loss: 0.0031, train acc: 0.9994, val loss: 0.0131, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14500] train loss: 0.0040, train acc: 0.9991, val loss: 0.0115, val acc: 0.9993  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14520] train loss: 0.0017, train acc: 0.9999, val loss: 0.0141, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14540] train loss: 0.0034, train acc: 0.9994, val loss: 0.0138, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14560] train loss: 0.0034, train acc: 0.9993, val loss: 0.0131, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14580] train loss: 0.0044, train acc: 0.9991, val loss: 0.0139, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14600] train loss: 0.0031, train acc: 0.9993, val loss: 0.0124, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14620] train loss: 0.0036, train acc: 0.9995, val loss: 0.0121, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14640] train loss: 0.0031, train acc: 0.9991, val loss: 0.0134, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14660] train loss: 0.0022, train acc: 0.9995, val loss: 0.0129, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14680] train loss: 0.0019, train acc: 0.9997, val loss: 0.0131, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14700] train loss: 0.0043, train acc: 0.9991, val loss: 0.0124, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14720] train loss: 0.0031, train acc: 0.9995, val loss: 0.0158, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14740] train loss: 0.0034, train acc: 0.9993, val loss: 0.0145, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14760] train loss: 0.0027, train acc: 0.9995, val loss: 0.0129, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14780] train loss: 0.0039, train acc: 0.9992, val loss: 0.0132, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14800] train loss: 0.0039, train acc: 0.9991, val loss: 0.0130, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14820] train loss: 0.0040, train acc: 0.9993, val loss: 0.0135, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14840] train loss: 0.0034, train acc: 0.9992, val loss: 0.0139, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14860] train loss: 0.0035, train acc: 0.9993, val loss: 0.0131, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14880] train loss: 0.0037, train acc: 0.9993, val loss: 0.0117, val acc: 0.9993  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14900] train loss: 0.0028, train acc: 0.9996, val loss: 0.0126, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14920] train loss: 0.0034, train acc: 0.9994, val loss: 0.0117, val acc: 0.9993  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14940] train loss: 0.0036, train acc: 0.9994, val loss: 0.0148, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14960] train loss: 0.0026, train acc: 0.9995, val loss: 0.0132, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 14980] train loss: 0.0037, train acc: 0.9993, val loss: 0.0136, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15000] train loss: 0.0052, train acc: 0.9989, val loss: 0.0141, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15020] train loss: 0.0036, train acc: 0.9991, val loss: 0.0129, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15040] train loss: 0.0016, train acc: 0.9998, val loss: 0.0136, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15060] train loss: 0.0028, train acc: 0.9995, val loss: 0.0136, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15080] train loss: 0.0024, train acc: 0.9994, val loss: 0.0146, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15100] train loss: 0.0028, train acc: 0.9995, val loss: 0.0145, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15120] train loss: 0.0035, train acc: 0.9993, val loss: 0.0141, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15140] train loss: 0.0037, train acc: 0.9994, val loss: 0.0149, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15160] train loss: 0.0029, train acc: 0.9994, val loss: 0.0143, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15180] train loss: 0.0033, train acc: 0.9993, val loss: 0.0138, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15200] train loss: 0.0035, train acc: 0.9993, val loss: 0.0120, val acc: 0.9993  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15220] train loss: 0.0030, train acc: 0.9993, val loss: 0.0149, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15240] train loss: 0.0038, train acc: 0.9989, val loss: 0.0131, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15260] train loss: 0.0043, train acc: 0.9993, val loss: 0.0141, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15280] train loss: 0.0040, train acc: 0.9992, val loss: 0.0133, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15300] train loss: 0.0045, train acc: 0.9989, val loss: 0.0125, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15320] train loss: 0.0042, train acc: 0.9991, val loss: 0.0131, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15340] train loss: 0.0029, train acc: 0.9995, val loss: 0.0126, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15360] train loss: 0.0033, train acc: 0.9993, val loss: 0.0132, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15380] train loss: 0.0049, train acc: 0.9992, val loss: 0.0140, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15400] train loss: 0.0038, train acc: 0.9990, val loss: 0.0144, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15420] train loss: 0.0022, train acc: 0.9996, val loss: 0.0131, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15440] train loss: 0.0038, train acc: 0.9991, val loss: 0.0153, val acc: 0.9987  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15460] train loss: 0.0043, train acc: 0.9989, val loss: 0.0125, val acc: 0.9993  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15480] train loss: 0.0037, train acc: 0.9993, val loss: 0.0150, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15500] train loss: 0.0027, train acc: 0.9992, val loss: 0.0146, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0012  @ epoch 14173 )\n",
      "[Epoch: 15520] train loss: 0.0023, train acc: 0.9993, val loss: 0.0165, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0011  @ epoch 15508 )\n",
      "[Epoch: 15540] train loss: 0.0033, train acc: 0.9992, val loss: 0.0147, val acc: 0.9993  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0011  @ epoch 15508 )\n",
      "[Epoch: 15560] train loss: 0.0021, train acc: 0.9996, val loss: 0.0164, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0011  @ epoch 15508 )\n",
      "[Epoch: 15580] train loss: 0.0020, train acc: 0.9996, val loss: 0.0161, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0011  @ epoch 15508 )\n",
      "[Epoch: 15600] train loss: 0.0027, train acc: 0.9995, val loss: 0.0158, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0011  @ epoch 15508 )\n",
      "[Epoch: 15620] train loss: 0.0019, train acc: 0.9994, val loss: 0.0164, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15640] train loss: 0.0024, train acc: 0.9993, val loss: 0.0172, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15660] train loss: 0.0018, train acc: 0.9994, val loss: 0.0150, val acc: 0.9993  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15680] train loss: 0.0028, train acc: 0.9993, val loss: 0.0161, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15700] train loss: 0.0026, train acc: 0.9993, val loss: 0.0163, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15720] train loss: 0.0028, train acc: 0.9994, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15740] train loss: 0.0027, train acc: 0.9993, val loss: 0.0179, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15760] train loss: 0.0026, train acc: 0.9993, val loss: 0.0166, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15780] train loss: 0.0021, train acc: 0.9995, val loss: 0.0168, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15800] train loss: 0.0023, train acc: 0.9994, val loss: 0.0141, val acc: 0.9993  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15820] train loss: 0.0029, train acc: 0.9991, val loss: 0.0160, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15840] train loss: 0.0025, train acc: 0.9993, val loss: 0.0172, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15860] train loss: 0.0030, train acc: 0.9992, val loss: 0.0155, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15880] train loss: 0.0019, train acc: 0.9994, val loss: 0.0176, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15900] train loss: 0.0024, train acc: 0.9993, val loss: 0.0172, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15920] train loss: 0.0030, train acc: 0.9991, val loss: 0.0151, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15940] train loss: 0.0025, train acc: 0.9995, val loss: 0.0148, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15960] train loss: 0.0031, train acc: 0.9993, val loss: 0.0158, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 15980] train loss: 0.0023, train acc: 0.9994, val loss: 0.0180, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 16000] train loss: 0.0031, train acc: 0.9991, val loss: 0.0168, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 16020] train loss: 0.0032, train acc: 0.9992, val loss: 0.0149, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 16040] train loss: 0.0023, train acc: 0.9995, val loss: 0.0154, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 16060] train loss: 0.0028, train acc: 0.9996, val loss: 0.0158, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0010  @ epoch 15613 )\n",
      "[Epoch: 16080] train loss: 0.0016, train acc: 0.9996, val loss: 0.0177, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0008  @ epoch 16065 )\n",
      "[Epoch: 16100] train loss: 0.0022, train acc: 0.9995, val loss: 0.0165, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0008  @ epoch 16065 )\n",
      "[Epoch: 16120] train loss: 0.0019, train acc: 0.9994, val loss: 0.0178, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0008  @ epoch 16065 )\n",
      "[Epoch: 16140] train loss: 0.0028, train acc: 0.9992, val loss: 0.0166, val acc: 0.9990  (best train acc: 0.9999, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16160] train loss: 0.0023, train acc: 0.9993, val loss: 0.0155, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16180] train loss: 0.0014, train acc: 0.9994, val loss: 0.0174, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16200] train loss: 0.0017, train acc: 0.9998, val loss: 0.0173, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16220] train loss: 0.0014, train acc: 0.9996, val loss: 0.0183, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16240] train loss: 0.0018, train acc: 0.9993, val loss: 0.0179, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16260] train loss: 0.0019, train acc: 0.9995, val loss: 0.0169, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16280] train loss: 0.0016, train acc: 0.9995, val loss: 0.0179, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16300] train loss: 0.0014, train acc: 0.9999, val loss: 0.0183, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16320] train loss: 0.0021, train acc: 0.9996, val loss: 0.0169, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16340] train loss: 0.0017, train acc: 0.9995, val loss: 0.0195, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16360] train loss: 0.0017, train acc: 0.9994, val loss: 0.0160, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16380] train loss: 0.0014, train acc: 0.9998, val loss: 0.0189, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16400] train loss: 0.0019, train acc: 0.9996, val loss: 0.0196, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16420] train loss: 0.0034, train acc: 0.9991, val loss: 0.0184, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16440] train loss: 0.0020, train acc: 0.9994, val loss: 0.0185, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16460] train loss: 0.0019, train acc: 0.9994, val loss: 0.0186, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16480] train loss: 0.0020, train acc: 0.9993, val loss: 0.0200, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16500] train loss: 0.0009, train acc: 0.9999, val loss: 0.0208, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16520] train loss: 0.0030, train acc: 0.9992, val loss: 0.0188, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16540] train loss: 0.0016, train acc: 0.9996, val loss: 0.0206, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16136 )\n",
      "[Epoch: 16560] train loss: 0.0015, train acc: 0.9997, val loss: 0.0195, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16580] train loss: 0.0018, train acc: 0.9995, val loss: 0.0214, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16600] train loss: 0.0020, train acc: 0.9993, val loss: 0.0194, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16620] train loss: 0.0027, train acc: 0.9991, val loss: 0.0192, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16640] train loss: 0.0017, train acc: 0.9995, val loss: 0.0184, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16660] train loss: 0.0015, train acc: 0.9996, val loss: 0.0270, val acc: 0.9980  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16680] train loss: 0.0356, train acc: 0.9935, val loss: 0.0131, val acc: 0.9973  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16700] train loss: 0.0059, train acc: 0.9991, val loss: 0.0111, val acc: 0.9980  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16720] train loss: 0.0044, train acc: 0.9992, val loss: 0.0124, val acc: 0.9980  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16740] train loss: 0.0066, train acc: 0.9989, val loss: 0.0125, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16760] train loss: 0.0063, train acc: 0.9988, val loss: 0.0134, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16780] train loss: 0.0038, train acc: 0.9991, val loss: 0.0195, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16800] train loss: 0.0034, train acc: 0.9990, val loss: 0.0190, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16820] train loss: 0.0023, train acc: 0.9994, val loss: 0.0181, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16840] train loss: 0.0019, train acc: 0.9996, val loss: 0.0183, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16860] train loss: 0.0021, train acc: 0.9996, val loss: 0.0191, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16880] train loss: 0.0025, train acc: 0.9994, val loss: 0.0182, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16900] train loss: 0.0021, train acc: 0.9993, val loss: 0.0198, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16920] train loss: 0.0023, train acc: 0.9994, val loss: 0.0191, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16940] train loss: 0.0018, train acc: 0.9995, val loss: 0.0198, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16960] train loss: 0.0018, train acc: 0.9993, val loss: 0.0201, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 16980] train loss: 0.0019, train acc: 0.9996, val loss: 0.0221, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17000] train loss: 0.0017, train acc: 0.9996, val loss: 0.0196, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17020] train loss: 0.0022, train acc: 0.9993, val loss: 0.0205, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17040] train loss: 0.0025, train acc: 0.9993, val loss: 0.0212, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17060] train loss: 0.0025, train acc: 0.9992, val loss: 0.0211, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17080] train loss: 0.0018, train acc: 0.9994, val loss: 0.0205, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17100] train loss: 0.0020, train acc: 0.9993, val loss: 0.0207, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17120] train loss: 0.0016, train acc: 0.9996, val loss: 0.0202, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17140] train loss: 0.0014, train acc: 0.9996, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17160] train loss: 0.0026, train acc: 0.9992, val loss: 0.0203, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17180] train loss: 0.0018, train acc: 0.9997, val loss: 0.0204, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17200] train loss: 0.0020, train acc: 0.9993, val loss: 0.0208, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17220] train loss: 0.0013, train acc: 0.9998, val loss: 0.0220, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17240] train loss: 0.0017, train acc: 0.9995, val loss: 0.0203, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0007  @ epoch 16547 )\n",
      "[Epoch: 17260] train loss: 0.0012, train acc: 0.9996, val loss: 0.0208, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17280] train loss: 0.0013, train acc: 0.9996, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17300] train loss: 0.0012, train acc: 0.9996, val loss: 0.0220, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17320] train loss: 0.0012, train acc: 0.9996, val loss: 0.0218, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17340] train loss: 0.0012, train acc: 0.9997, val loss: 0.0204, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17360] train loss: 0.0013, train acc: 0.9996, val loss: 0.0211, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17380] train loss: 0.0011, train acc: 0.9998, val loss: 0.0223, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17400] train loss: 0.0012, train acc: 0.9996, val loss: 0.0203, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17420] train loss: 0.0018, train acc: 0.9993, val loss: 0.0213, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17440] train loss: 0.0008, train acc: 0.9999, val loss: 0.0216, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17460] train loss: 0.0010, train acc: 0.9997, val loss: 0.0222, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17480] train loss: 0.0016, train acc: 0.9996, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17500] train loss: 0.0012, train acc: 0.9996, val loss: 0.0221, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17520] train loss: 0.0015, train acc: 0.9995, val loss: 0.0218, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17540] train loss: 0.0016, train acc: 0.9996, val loss: 0.0219, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17560] train loss: 0.0017, train acc: 0.9994, val loss: 0.0219, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17580] train loss: 0.0014, train acc: 0.9995, val loss: 0.0218, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17600] train loss: 0.0011, train acc: 0.9997, val loss: 0.0211, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17620] train loss: 0.0017, train acc: 0.9993, val loss: 0.0211, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17640] train loss: 0.0011, train acc: 0.9997, val loss: 0.0195, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17660] train loss: 0.0015, train acc: 0.9993, val loss: 0.0208, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17680] train loss: 0.0014, train acc: 0.9994, val loss: 0.0210, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17700] train loss: 0.0011, train acc: 0.9996, val loss: 0.0219, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17720] train loss: 0.0009, train acc: 0.9997, val loss: 0.0219, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17740] train loss: 0.0013, train acc: 0.9996, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17760] train loss: 0.0012, train acc: 0.9995, val loss: 0.0213, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17780] train loss: 0.0010, train acc: 0.9998, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17800] train loss: 0.0010, train acc: 0.9996, val loss: 0.0217, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17820] train loss: 0.0012, train acc: 0.9995, val loss: 0.0213, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17840] train loss: 0.0008, train acc: 0.9999, val loss: 0.0212, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17860] train loss: 0.0012, train acc: 0.9997, val loss: 0.0217, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17880] train loss: 0.0017, train acc: 0.9996, val loss: 0.0205, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17900] train loss: 0.0008, train acc: 0.9998, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17920] train loss: 0.0010, train acc: 0.9997, val loss: 0.0202, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17940] train loss: 0.0013, train acc: 0.9996, val loss: 0.0208, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17960] train loss: 0.0012, train acc: 0.9995, val loss: 0.0205, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0005  @ epoch 17256 )\n",
      "[Epoch: 17980] train loss: 0.0005, train acc: 1.0000, val loss: 0.0202, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0003  @ epoch 17968 )\n",
      "[Epoch: 18000] train loss: 0.0006, train acc: 0.9999, val loss: 0.0214, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0003  @ epoch 17968 )\n",
      "[Epoch: 18020] train loss: 0.0007, train acc: 0.9999, val loss: 0.0205, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0003  @ epoch 17968 )\n",
      "[Epoch: 18040] train loss: 0.0005, train acc: 0.9999, val loss: 0.0220, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0003  @ epoch 17968 )\n",
      "[Epoch: 18060] train loss: 0.0005, train acc: 0.9999, val loss: 0.0213, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0003  @ epoch 17968 )\n",
      "[Epoch: 18080] train loss: 0.0005, train acc: 0.9998, val loss: 0.0209, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0003  @ epoch 17968 )\n",
      "[Epoch: 18100] train loss: 0.0009, train acc: 0.9999, val loss: 0.0204, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0003  @ epoch 18083 )\n",
      "[Epoch: 18120] train loss: 0.0007, train acc: 0.9997, val loss: 0.0205, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0003  @ epoch 18083 )\n",
      "[Epoch: 18140] train loss: 0.0005, train acc: 0.9999, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0003  @ epoch 18083 )\n",
      "[Epoch: 18160] train loss: 0.0010, train acc: 0.9996, val loss: 0.0213, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0003  @ epoch 18083 )\n",
      "[Epoch: 18180] train loss: 0.0011, train acc: 0.9996, val loss: 0.0216, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18164 )\n",
      "[Epoch: 18200] train loss: 0.0008, train acc: 0.9997, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18164 )\n",
      "[Epoch: 18220] train loss: 0.0010, train acc: 0.9996, val loss: 0.0214, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18164 )\n",
      "[Epoch: 18240] train loss: 0.0011, train acc: 0.9996, val loss: 0.0215, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18164 )\n",
      "[Epoch: 18260] train loss: 0.0012, train acc: 0.9996, val loss: 0.0204, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18164 )\n",
      "[Epoch: 18280] train loss: 0.0008, train acc: 0.9996, val loss: 0.0202, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18164 )\n",
      "[Epoch: 18300] train loss: 0.0012, train acc: 0.9997, val loss: 0.0192, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18164 )\n",
      "[Epoch: 18320] train loss: 0.0012, train acc: 0.9996, val loss: 0.0212, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18164 )\n",
      "[Epoch: 18340] train loss: 0.0016, train acc: 0.9996, val loss: 0.0194, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18164 )\n",
      "[Epoch: 18360] train loss: 0.0008, train acc: 0.9996, val loss: 0.0217, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18164 )\n",
      "[Epoch: 18380] train loss: 0.0009, train acc: 0.9997, val loss: 0.0196, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18164 )\n",
      "[Epoch: 18400] train loss: 0.0007, train acc: 0.9999, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18420] train loss: 0.0010, train acc: 0.9997, val loss: 0.0212, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18440] train loss: 0.0007, train acc: 0.9999, val loss: 0.0214, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18460] train loss: 0.0008, train acc: 0.9996, val loss: 0.0203, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18480] train loss: 0.0013, train acc: 0.9996, val loss: 0.0208, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18500] train loss: 0.0012, train acc: 0.9996, val loss: 0.0202, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18520] train loss: 0.0013, train acc: 0.9995, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18540] train loss: 0.0003, train acc: 0.9999, val loss: 0.0209, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18560] train loss: 0.0013, train acc: 0.9996, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18580] train loss: 0.0004, train acc: 0.9999, val loss: 0.0199, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18600] train loss: 0.0003, train acc: 1.0000, val loss: 0.0204, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18620] train loss: 0.0009, train acc: 0.9997, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18640] train loss: 0.0014, train acc: 0.9996, val loss: 0.0205, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18660] train loss: 0.0005, train acc: 0.9999, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18680] train loss: 0.0006, train acc: 0.9998, val loss: 0.0209, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18700] train loss: 0.0016, train acc: 0.9995, val loss: 0.0203, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18720] train loss: 0.0006, train acc: 0.9998, val loss: 0.0221, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18740] train loss: 0.0007, train acc: 0.9998, val loss: 0.0198, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18760] train loss: 0.0007, train acc: 0.9998, val loss: 0.0200, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18780] train loss: 0.0004, train acc: 1.0000, val loss: 0.0196, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18800] train loss: 0.0005, train acc: 0.9999, val loss: 0.0201, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18820] train loss: 0.0012, train acc: 0.9994, val loss: 0.0193, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18840] train loss: 0.0007, train acc: 0.9998, val loss: 0.0198, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18860] train loss: 0.0007, train acc: 0.9998, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18880] train loss: 0.0009, train acc: 0.9996, val loss: 0.0200, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18900] train loss: 0.0005, train acc: 0.9998, val loss: 0.0204, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18920] train loss: 0.0005, train acc: 0.9999, val loss: 0.0199, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18940] train loss: 0.0010, train acc: 0.9996, val loss: 0.0190, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18960] train loss: 0.0003, train acc: 1.0000, val loss: 0.0211, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 18980] train loss: 0.0009, train acc: 0.9996, val loss: 0.0202, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19000] train loss: 0.0008, train acc: 0.9996, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19020] train loss: 0.0007, train acc: 0.9999, val loss: 0.0198, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19040] train loss: 0.0008, train acc: 0.9996, val loss: 0.0201, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19060] train loss: 0.0010, train acc: 0.9997, val loss: 0.0205, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19080] train loss: 0.0005, train acc: 0.9999, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19100] train loss: 0.0011, train acc: 0.9997, val loss: 0.0194, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19120] train loss: 0.0009, train acc: 0.9997, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19140] train loss: 0.0010, train acc: 0.9996, val loss: 0.0208, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19160] train loss: 0.0005, train acc: 0.9999, val loss: 0.0220, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19180] train loss: 0.0003, train acc: 0.9999, val loss: 0.0209, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19200] train loss: 0.0010, train acc: 0.9997, val loss: 0.0223, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19220] train loss: 0.0013, train acc: 0.9996, val loss: 0.0203, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19240] train loss: 0.0007, train acc: 0.9997, val loss: 0.0209, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19260] train loss: 0.0006, train acc: 0.9998, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19280] train loss: 0.0006, train acc: 0.9998, val loss: 0.0220, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19300] train loss: 0.0006, train acc: 0.9998, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19320] train loss: 0.0005, train acc: 0.9999, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19340] train loss: 0.0007, train acc: 0.9999, val loss: 0.0197, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19360] train loss: 0.0007, train acc: 0.9998, val loss: 0.0198, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19380] train loss: 0.0006, train acc: 0.9997, val loss: 0.0193, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19400] train loss: 0.0007, train acc: 0.9997, val loss: 0.0199, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19420] train loss: 0.0005, train acc: 0.9999, val loss: 0.0216, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19440] train loss: 0.0003, train acc: 0.9999, val loss: 0.0205, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19460] train loss: 0.0003, train acc: 1.0000, val loss: 0.0210, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19480] train loss: 0.0008, train acc: 0.9997, val loss: 0.0199, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19500] train loss: 0.0004, train acc: 0.9999, val loss: 0.0191, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19520] train loss: 0.0004, train acc: 0.9999, val loss: 0.0208, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19540] train loss: 0.0004, train acc: 0.9998, val loss: 0.0203, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19560] train loss: 0.0006, train acc: 0.9998, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19580] train loss: 0.0003, train acc: 0.9999, val loss: 0.0209, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19600] train loss: 0.0005, train acc: 0.9999, val loss: 0.0199, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19620] train loss: 0.0006, train acc: 0.9999, val loss: 0.0191, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19640] train loss: 0.0008, train acc: 0.9996, val loss: 0.0201, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19660] train loss: 0.0007, train acc: 0.9999, val loss: 0.0206, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19680] train loss: 0.0007, train acc: 0.9999, val loss: 0.0209, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19700] train loss: 0.0003, train acc: 1.0000, val loss: 0.0197, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19720] train loss: 0.0006, train acc: 0.9998, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19740] train loss: 0.0004, train acc: 1.0000, val loss: 0.0194, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19760] train loss: 0.0005, train acc: 0.9998, val loss: 0.0203, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19780] train loss: 0.0009, train acc: 0.9996, val loss: 0.0189, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19800] train loss: 0.0010, train acc: 0.9996, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19820] train loss: 0.0006, train acc: 0.9998, val loss: 0.0196, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19840] train loss: 0.0015, train acc: 0.9996, val loss: 0.0193, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19860] train loss: 0.0009, train acc: 0.9996, val loss: 0.0200, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19880] train loss: 0.0005, train acc: 0.9999, val loss: 0.0186, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19900] train loss: 0.0006, train acc: 0.9998, val loss: 0.0193, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19920] train loss: 0.0004, train acc: 0.9999, val loss: 0.0199, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19940] train loss: 0.0005, train acc: 0.9999, val loss: 0.0192, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19960] train loss: 0.0004, train acc: 0.9999, val loss: 0.0210, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 19980] train loss: 0.0004, train acc: 0.9999, val loss: 0.0198, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20000] train loss: 0.0003, train acc: 1.0000, val loss: 0.0201, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20020] train loss: 0.0008, train acc: 0.9996, val loss: 0.0198, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20040] train loss: 0.0009, train acc: 0.9998, val loss: 0.0196, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20060] train loss: 0.0008, train acc: 0.9996, val loss: 0.0216, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20080] train loss: 0.0011, train acc: 0.9996, val loss: 0.0189, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20100] train loss: 0.0007, train acc: 0.9997, val loss: 0.0207, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20120] train loss: 0.0007, train acc: 0.9999, val loss: 0.0188, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20140] train loss: 0.0006, train acc: 0.9999, val loss: 0.0187, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20160] train loss: 0.0009, train acc: 0.9999, val loss: 0.0193, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20180] train loss: 0.0004, train acc: 0.9999, val loss: 0.0190, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20200] train loss: 0.0003, train acc: 0.9999, val loss: 0.0200, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20220] train loss: 0.0004, train acc: 0.9999, val loss: 0.0180, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20240] train loss: 0.0005, train acc: 0.9999, val loss: 0.0187, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20260] train loss: 0.0008, train acc: 0.9997, val loss: 0.0180, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20280] train loss: 0.0003, train acc: 1.0000, val loss: 0.0177, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 18386 )\n",
      "[Epoch: 20300] train loss: 0.0006, train acc: 0.9999, val loss: 0.0174, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 20284 )\n",
      "[Epoch: 20320] train loss: 0.0011, train acc: 0.9996, val loss: 0.0178, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0002  @ epoch 20284 )\n",
      "[Epoch: 20340] train loss: 0.0004, train acc: 0.9999, val loss: 0.0178, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20360] train loss: 0.0005, train acc: 0.9999, val loss: 0.0177, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20380] train loss: 0.0007, train acc: 0.9998, val loss: 0.0171, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20400] train loss: 0.0005, train acc: 0.9999, val loss: 0.0180, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20420] train loss: 0.0007, train acc: 0.9998, val loss: 0.0175, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20440] train loss: 0.0009, train acc: 0.9997, val loss: 0.0170, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20460] train loss: 0.0004, train acc: 0.9999, val loss: 0.0187, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20480] train loss: 0.0003, train acc: 0.9999, val loss: 0.0173, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20500] train loss: 0.0006, train acc: 0.9999, val loss: 0.0162, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20520] train loss: 0.0009, train acc: 0.9998, val loss: 0.0165, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20540] train loss: 0.0003, train acc: 0.9999, val loss: 0.0168, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20560] train loss: 0.0006, train acc: 0.9998, val loss: 0.0165, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20580] train loss: 0.0007, train acc: 0.9999, val loss: 0.0160, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20600] train loss: 0.0006, train acc: 0.9999, val loss: 0.0176, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20620] train loss: 0.0002, train acc: 1.0000, val loss: 0.0180, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20640] train loss: 0.0006, train acc: 0.9998, val loss: 0.0160, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20660] train loss: 0.0005, train acc: 0.9999, val loss: 0.0162, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20680] train loss: 0.0007, train acc: 0.9996, val loss: 0.0161, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20700] train loss: 0.0007, train acc: 0.9999, val loss: 0.0170, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20720] train loss: 0.0005, train acc: 0.9999, val loss: 0.0156, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20740] train loss: 0.0003, train acc: 1.0000, val loss: 0.0166, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20760] train loss: 0.0005, train acc: 0.9999, val loss: 0.0169, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20780] train loss: 0.0003, train acc: 0.9999, val loss: 0.0158, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20800] train loss: 0.0010, train acc: 0.9997, val loss: 0.0161, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20820] train loss: 0.0005, train acc: 0.9999, val loss: 0.0164, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20840] train loss: 0.0005, train acc: 0.9999, val loss: 0.0169, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20860] train loss: 0.0003, train acc: 0.9999, val loss: 0.0157, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20880] train loss: 0.0004, train acc: 0.9999, val loss: 0.0158, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20900] train loss: 0.0004, train acc: 0.9999, val loss: 0.0165, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20920] train loss: 0.0004, train acc: 0.9999, val loss: 0.0181, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20940] train loss: 0.0004, train acc: 0.9999, val loss: 0.0175, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20960] train loss: 0.0004, train acc: 0.9999, val loss: 0.0166, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20330 )\n",
      "[Epoch: 20980] train loss: 0.0004, train acc: 0.9999, val loss: 0.0163, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21000] train loss: 0.0005, train acc: 0.9998, val loss: 0.0168, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21020] train loss: 0.0005, train acc: 0.9999, val loss: 0.0162, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21040] train loss: 0.0005, train acc: 0.9999, val loss: 0.0161, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21060] train loss: 0.0006, train acc: 0.9999, val loss: 0.0160, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21080] train loss: 0.0004, train acc: 0.9999, val loss: 0.0166, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21100] train loss: 0.0009, train acc: 0.9996, val loss: 0.0169, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21120] train loss: 0.0005, train acc: 0.9999, val loss: 0.0158, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21140] train loss: 0.0006, train acc: 0.9998, val loss: 0.0143, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21160] train loss: 0.0008, train acc: 0.9997, val loss: 0.0150, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21180] train loss: 0.0005, train acc: 0.9998, val loss: 0.0153, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21200] train loss: 0.0006, train acc: 0.9999, val loss: 0.0159, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21220] train loss: 0.0002, train acc: 1.0000, val loss: 0.0152, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21240] train loss: 0.0002, train acc: 1.0000, val loss: 0.0157, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21260] train loss: 0.0014, train acc: 0.9994, val loss: 0.0151, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21280] train loss: 0.0004, train acc: 0.9999, val loss: 0.0149, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21300] train loss: 0.0007, train acc: 0.9998, val loss: 0.0150, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21320] train loss: 0.0006, train acc: 0.9998, val loss: 0.0157, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21340] train loss: 0.0004, train acc: 0.9999, val loss: 0.0157, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21360] train loss: 0.0004, train acc: 1.0000, val loss: 0.0147, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21380] train loss: 0.0002, train acc: 1.0000, val loss: 0.0154, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21400] train loss: 0.0002, train acc: 0.9999, val loss: 0.0155, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21420] train loss: 0.0003, train acc: 0.9999, val loss: 0.0151, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21440] train loss: 0.0004, train acc: 0.9999, val loss: 0.0157, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21460] train loss: 0.0006, train acc: 0.9999, val loss: 0.0167, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21480] train loss: 0.0005, train acc: 0.9999, val loss: 0.0146, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21500] train loss: 0.0006, train acc: 0.9999, val loss: 0.0159, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21520] train loss: 0.0005, train acc: 0.9999, val loss: 0.0148, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21540] train loss: 0.0012, train acc: 0.9996, val loss: 0.0150, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21560] train loss: 0.0006, train acc: 0.9999, val loss: 0.0159, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21580] train loss: 0.0007, train acc: 0.9998, val loss: 0.0154, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21600] train loss: 0.0003, train acc: 0.9999, val loss: 0.0159, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21620] train loss: 0.0004, train acc: 0.9999, val loss: 0.0161, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21640] train loss: 0.0007, train acc: 0.9998, val loss: 0.0160, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21660] train loss: 0.0002, train acc: 0.9999, val loss: 0.0164, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21680] train loss: 0.0009, train acc: 0.9997, val loss: 0.0160, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21700] train loss: 0.0008, train acc: 0.9998, val loss: 0.0156, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21720] train loss: 0.0009, train acc: 0.9997, val loss: 0.0168, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21740] train loss: 0.0005, train acc: 0.9999, val loss: 0.0148, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21760] train loss: 0.0004, train acc: 0.9999, val loss: 0.0156, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21780] train loss: 0.0002, train acc: 1.0000, val loss: 0.0148, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21800] train loss: 0.0007, train acc: 0.9997, val loss: 0.0156, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21820] train loss: 0.0005, train acc: 0.9998, val loss: 0.0173, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21840] train loss: 0.0005, train acc: 0.9999, val loss: 0.0155, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21860] train loss: 0.0005, train acc: 0.9999, val loss: 0.0150, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21880] train loss: 0.0005, train acc: 0.9999, val loss: 0.0150, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21900] train loss: 0.0008, train acc: 0.9998, val loss: 0.0158, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21920] train loss: 0.0004, train acc: 0.9999, val loss: 0.0151, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21940] train loss: 0.0002, train acc: 0.9999, val loss: 0.0153, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21960] train loss: 0.0009, train acc: 0.9997, val loss: 0.0153, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 21980] train loss: 0.0004, train acc: 0.9999, val loss: 0.0158, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22000] train loss: 0.0006, train acc: 0.9997, val loss: 0.0164, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22020] train loss: 0.0006, train acc: 0.9997, val loss: 0.0147, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22040] train loss: 0.0008, train acc: 0.9998, val loss: 0.0149, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22060] train loss: 0.0007, train acc: 0.9998, val loss: 0.0156, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22080] train loss: 0.0004, train acc: 0.9999, val loss: 0.0150, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22100] train loss: 0.0008, train acc: 0.9996, val loss: 0.0156, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22120] train loss: 0.0004, train acc: 0.9999, val loss: 0.0151, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22140] train loss: 0.0003, train acc: 1.0000, val loss: 0.0149, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22160] train loss: 0.0008, train acc: 0.9999, val loss: 0.0146, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22180] train loss: 0.0153, train acc: 0.9963, val loss: 0.0108, val acc: 0.9970  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22200] train loss: 0.0067, train acc: 0.9978, val loss: 0.0133, val acc: 0.9970  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22220] train loss: 0.0036, train acc: 0.9987, val loss: 0.0105, val acc: 0.9980  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22240] train loss: 0.0025, train acc: 0.9993, val loss: 0.0125, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22260] train loss: 0.0021, train acc: 0.9995, val loss: 0.0131, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22280] train loss: 0.0018, train acc: 0.9995, val loss: 0.0128, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22300] train loss: 0.0017, train acc: 0.9996, val loss: 0.0129, val acc: 0.9976  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22320] train loss: 0.0015, train acc: 0.9996, val loss: 0.0124, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22340] train loss: 0.0017, train acc: 0.9995, val loss: 0.0127, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22360] train loss: 0.0011, train acc: 0.9997, val loss: 0.0128, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22380] train loss: 0.0020, train acc: 0.9996, val loss: 0.0143, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22400] train loss: 0.0012, train acc: 0.9997, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22420] train loss: 0.0007, train acc: 0.9998, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22440] train loss: 0.0021, train acc: 0.9995, val loss: 0.0129, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22460] train loss: 0.0015, train acc: 0.9997, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22480] train loss: 0.0006, train acc: 1.0000, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22500] train loss: 0.0011, train acc: 0.9999, val loss: 0.0129, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22520] train loss: 0.0017, train acc: 0.9996, val loss: 0.0130, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22540] train loss: 0.0009, train acc: 0.9998, val loss: 0.0130, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22560] train loss: 0.0010, train acc: 0.9998, val loss: 0.0137, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22580] train loss: 0.0009, train acc: 0.9998, val loss: 0.0141, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22600] train loss: 0.0008, train acc: 0.9999, val loss: 0.0134, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22620] train loss: 0.0004, train acc: 0.9999, val loss: 0.0139, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22640] train loss: 0.0004, train acc: 0.9999, val loss: 0.0130, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22660] train loss: 0.0004, train acc: 1.0000, val loss: 0.0131, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22680] train loss: 0.0016, train acc: 0.9996, val loss: 0.0135, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22700] train loss: 0.0004, train acc: 1.0000, val loss: 0.0137, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22720] train loss: 0.0008, train acc: 0.9999, val loss: 0.0141, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22740] train loss: 0.0005, train acc: 0.9999, val loss: 0.0142, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22760] train loss: 0.0007, train acc: 0.9999, val loss: 0.0138, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22780] train loss: 0.0008, train acc: 0.9999, val loss: 0.0135, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22800] train loss: 0.0011, train acc: 0.9998, val loss: 0.0150, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22820] train loss: 0.0003, train acc: 1.0000, val loss: 0.0132, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22840] train loss: 0.0014, train acc: 0.9997, val loss: 0.0136, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22860] train loss: 0.0008, train acc: 0.9999, val loss: 0.0142, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22880] train loss: 0.0013, train acc: 0.9996, val loss: 0.0133, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22900] train loss: 0.0006, train acc: 0.9999, val loss: 0.0129, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22920] train loss: 0.0008, train acc: 0.9998, val loss: 0.0135, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22940] train loss: 0.0014, train acc: 0.9996, val loss: 0.0133, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22960] train loss: 0.0006, train acc: 0.9999, val loss: 0.0141, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 22980] train loss: 0.0009, train acc: 0.9998, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23000] train loss: 0.0009, train acc: 0.9999, val loss: 0.0147, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23020] train loss: 0.0008, train acc: 0.9998, val loss: 0.0126, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23040] train loss: 0.0013, train acc: 0.9997, val loss: 0.0123, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23060] train loss: 0.0010, train acc: 0.9998, val loss: 0.0126, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23080] train loss: 0.0007, train acc: 0.9999, val loss: 0.0127, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23100] train loss: 0.0007, train acc: 0.9999, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23120] train loss: 0.0015, train acc: 0.9996, val loss: 0.0135, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23140] train loss: 0.0011, train acc: 0.9996, val loss: 0.0136, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23160] train loss: 0.0006, train acc: 0.9999, val loss: 0.0131, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23180] train loss: 0.0014, train acc: 0.9996, val loss: 0.0137, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23200] train loss: 0.0010, train acc: 0.9998, val loss: 0.0133, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23220] train loss: 0.0003, train acc: 1.0000, val loss: 0.0131, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23240] train loss: 0.0006, train acc: 0.9999, val loss: 0.0143, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23260] train loss: 0.0007, train acc: 0.9999, val loss: 0.0128, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23280] train loss: 0.0008, train acc: 0.9998, val loss: 0.0130, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23300] train loss: 0.0008, train acc: 0.9999, val loss: 0.0128, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23320] train loss: 0.0006, train acc: 0.9999, val loss: 0.0126, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23340] train loss: 0.0007, train acc: 0.9999, val loss: 0.0135, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23360] train loss: 0.0011, train acc: 0.9998, val loss: 0.0128, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23380] train loss: 0.0007, train acc: 0.9999, val loss: 0.0128, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23400] train loss: 0.0006, train acc: 0.9999, val loss: 0.0131, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23420] train loss: 0.0008, train acc: 0.9998, val loss: 0.0127, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23440] train loss: 0.0010, train acc: 0.9999, val loss: 0.0127, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23460] train loss: 0.0004, train acc: 0.9999, val loss: 0.0132, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23480] train loss: 0.0005, train acc: 0.9999, val loss: 0.0132, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23500] train loss: 0.0009, train acc: 0.9997, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23520] train loss: 0.0004, train acc: 0.9999, val loss: 0.0124, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23540] train loss: 0.0005, train acc: 0.9999, val loss: 0.0123, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23560] train loss: 0.0005, train acc: 0.9999, val loss: 0.0123, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23580] train loss: 0.0005, train acc: 0.9999, val loss: 0.0117, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23600] train loss: 0.0007, train acc: 0.9998, val loss: 0.0127, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23620] train loss: 0.0002, train acc: 1.0000, val loss: 0.0120, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23640] train loss: 0.0004, train acc: 0.9999, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23660] train loss: 0.0005, train acc: 0.9999, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23680] train loss: 0.0010, train acc: 0.9997, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23700] train loss: 0.0007, train acc: 0.9998, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23720] train loss: 0.0009, train acc: 0.9998, val loss: 0.0119, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23740] train loss: 0.0002, train acc: 1.0000, val loss: 0.0120, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23760] train loss: 0.0005, train acc: 0.9998, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23780] train loss: 0.0016, train acc: 0.9996, val loss: 0.0122, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23800] train loss: 0.0007, train acc: 0.9999, val loss: 0.0127, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23820] train loss: 0.0010, train acc: 0.9997, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23840] train loss: 0.0008, train acc: 0.9999, val loss: 0.0116, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23860] train loss: 0.0008, train acc: 0.9998, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23880] train loss: 0.0004, train acc: 0.9999, val loss: 0.0124, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23900] train loss: 0.0006, train acc: 0.9999, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23920] train loss: 0.0004, train acc: 0.9999, val loss: 0.0120, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23940] train loss: 0.0006, train acc: 0.9998, val loss: 0.0116, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23960] train loss: 0.0003, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 23980] train loss: 0.0013, train acc: 0.9996, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24000] train loss: 0.0003, train acc: 1.0000, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24020] train loss: 0.0004, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24040] train loss: 0.0008, train acc: 0.9997, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24060] train loss: 0.0007, train acc: 0.9998, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24080] train loss: 0.0009, train acc: 0.9997, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24100] train loss: 0.0006, train acc: 0.9999, val loss: 0.0110, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24120] train loss: 0.0012, train acc: 0.9998, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24140] train loss: 0.0009, train acc: 0.9997, val loss: 0.0114, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24160] train loss: 0.0009, train acc: 0.9998, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24180] train loss: 0.0016, train acc: 0.9995, val loss: 0.0115, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24200] train loss: 0.0007, train acc: 0.9999, val loss: 0.0110, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24220] train loss: 0.0014, train acc: 0.9996, val loss: 0.0111, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24240] train loss: 0.0009, train acc: 0.9998, val loss: 0.0111, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24260] train loss: 0.0009, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24280] train loss: 0.0008, train acc: 0.9998, val loss: 0.0119, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24300] train loss: 0.0007, train acc: 0.9998, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24320] train loss: 0.0004, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24340] train loss: 0.0011, train acc: 0.9996, val loss: 0.0117, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24360] train loss: 0.0003, train acc: 0.9999, val loss: 0.0127, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24380] train loss: 0.0005, train acc: 0.9999, val loss: 0.0120, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24400] train loss: 0.0004, train acc: 0.9999, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24420] train loss: 0.0009, train acc: 0.9996, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24440] train loss: 0.0004, train acc: 1.0000, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24460] train loss: 0.0008, train acc: 0.9998, val loss: 0.0120, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24480] train loss: 0.0005, train acc: 0.9999, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24500] train loss: 0.0009, train acc: 0.9997, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24520] train loss: 0.0006, train acc: 0.9998, val loss: 0.0110, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24540] train loss: 0.0009, train acc: 0.9998, val loss: 0.0110, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24560] train loss: 0.0008, train acc: 0.9999, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24580] train loss: 0.0008, train acc: 0.9996, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24600] train loss: 0.0009, train acc: 0.9997, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24620] train loss: 0.0010, train acc: 0.9998, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24640] train loss: 0.0006, train acc: 0.9999, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24660] train loss: 0.0003, train acc: 1.0000, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24680] train loss: 0.0010, train acc: 0.9996, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24700] train loss: 0.0006, train acc: 0.9999, val loss: 0.0122, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24720] train loss: 0.0005, train acc: 0.9999, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24740] train loss: 0.0010, train acc: 0.9997, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24760] train loss: 0.0008, train acc: 0.9998, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24780] train loss: 0.0007, train acc: 0.9999, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24800] train loss: 0.0010, train acc: 0.9997, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24820] train loss: 0.0009, train acc: 0.9998, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24840] train loss: 0.0004, train acc: 0.9999, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24860] train loss: 0.0005, train acc: 0.9999, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24880] train loss: 0.0004, train acc: 1.0000, val loss: 0.0109, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24900] train loss: 0.0010, train acc: 0.9996, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24920] train loss: 0.0005, train acc: 0.9999, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24940] train loss: 0.0012, train acc: 0.9996, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24960] train loss: 0.0008, train acc: 0.9999, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 24980] train loss: 0.0009, train acc: 0.9997, val loss: 0.0132, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25000] train loss: 0.0007, train acc: 0.9999, val loss: 0.0122, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25020] train loss: 0.0013, train acc: 0.9997, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25040] train loss: 0.0007, train acc: 0.9999, val loss: 0.0118, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25060] train loss: 0.0007, train acc: 0.9998, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25080] train loss: 0.0015, train acc: 0.9997, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25100] train loss: 0.0004, train acc: 0.9999, val loss: 0.0110, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25120] train loss: 0.0009, train acc: 0.9998, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25140] train loss: 0.0010, train acc: 0.9998, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25160] train loss: 0.0004, train acc: 0.9999, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25180] train loss: 0.0011, train acc: 0.9997, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25200] train loss: 0.0007, train acc: 0.9999, val loss: 0.0124, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25220] train loss: 0.0012, train acc: 0.9996, val loss: 0.0127, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25240] train loss: 0.0005, train acc: 0.9999, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25260] train loss: 0.0008, train acc: 0.9998, val loss: 0.0109, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25280] train loss: 0.0004, train acc: 0.9999, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25300] train loss: 0.0006, train acc: 0.9999, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25320] train loss: 0.0010, train acc: 0.9998, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25340] train loss: 0.0002, train acc: 1.0000, val loss: 0.0132, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25360] train loss: 0.0010, train acc: 0.9998, val loss: 0.0129, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25380] train loss: 0.0005, train acc: 0.9999, val loss: 0.0120, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25400] train loss: 0.0005, train acc: 0.9999, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25420] train loss: 0.0009, train acc: 0.9996, val loss: 0.0122, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25440] train loss: 0.0020, train acc: 0.9994, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25460] train loss: 0.0006, train acc: 0.9999, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25480] train loss: 0.0012, train acc: 0.9996, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25500] train loss: 0.0005, train acc: 0.9999, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25520] train loss: 0.0003, train acc: 0.9999, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25540] train loss: 0.0006, train acc: 0.9999, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25560] train loss: 0.0010, train acc: 0.9999, val loss: 0.0123, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25580] train loss: 0.0009, train acc: 0.9998, val loss: 0.0127, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25600] train loss: 0.0009, train acc: 0.9998, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25620] train loss: 0.0005, train acc: 0.9999, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25640] train loss: 0.0005, train acc: 0.9999, val loss: 0.0122, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25660] train loss: 0.0008, train acc: 0.9998, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25680] train loss: 0.0014, train acc: 0.9996, val loss: 0.0125, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25700] train loss: 0.0010, train acc: 0.9998, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25720] train loss: 0.0008, train acc: 0.9998, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25740] train loss: 0.0005, train acc: 0.9998, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25760] train loss: 0.0008, train acc: 0.9999, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25780] train loss: 0.0006, train acc: 0.9999, val loss: 0.0124, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25800] train loss: 0.0005, train acc: 0.9999, val loss: 0.0136, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25820] train loss: 0.0006, train acc: 0.9999, val loss: 0.0133, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25840] train loss: 0.0010, train acc: 0.9998, val loss: 0.0128, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25860] train loss: 0.0006, train acc: 0.9999, val loss: 0.0133, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25880] train loss: 0.0005, train acc: 0.9999, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25900] train loss: 0.0009, train acc: 0.9998, val loss: 0.0126, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25920] train loss: 0.0010, train acc: 0.9998, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25940] train loss: 0.0010, train acc: 0.9998, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25960] train loss: 0.0011, train acc: 0.9996, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 25980] train loss: 0.0007, train acc: 0.9998, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26000] train loss: 0.0007, train acc: 0.9999, val loss: 0.0130, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26020] train loss: 0.0013, train acc: 0.9995, val loss: 0.0129, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26040] train loss: 0.0011, train acc: 0.9997, val loss: 0.0139, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26060] train loss: 0.0011, train acc: 0.9997, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26080] train loss: 0.0006, train acc: 0.9999, val loss: 0.0131, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26100] train loss: 0.0003, train acc: 1.0000, val loss: 0.0124, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26120] train loss: 0.0007, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26140] train loss: 0.0004, train acc: 0.9999, val loss: 0.0124, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26160] train loss: 0.0004, train acc: 0.9999, val loss: 0.0123, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26180] train loss: 0.0014, train acc: 0.9996, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26200] train loss: 0.0008, train acc: 0.9998, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26220] train loss: 0.0009, train acc: 0.9998, val loss: 0.0118, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26240] train loss: 0.0009, train acc: 0.9996, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26260] train loss: 0.0007, train acc: 0.9999, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26280] train loss: 0.0004, train acc: 0.9999, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26300] train loss: 0.0006, train acc: 0.9998, val loss: 0.0129, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26320] train loss: 0.0008, train acc: 0.9997, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26340] train loss: 0.0010, train acc: 0.9998, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26360] train loss: 0.0009, train acc: 0.9997, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26380] train loss: 0.0003, train acc: 1.0000, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26400] train loss: 0.0019, train acc: 0.9996, val loss: 0.0120, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26420] train loss: 0.0006, train acc: 0.9999, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26440] train loss: 0.0008, train acc: 0.9997, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26460] train loss: 0.0006, train acc: 0.9999, val loss: 0.0133, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26480] train loss: 0.0016, train acc: 0.9995, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26500] train loss: 0.0005, train acc: 0.9999, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26520] train loss: 0.0009, train acc: 0.9998, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26540] train loss: 0.0007, train acc: 0.9998, val loss: 0.0129, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26560] train loss: 0.0007, train acc: 0.9999, val loss: 0.0129, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26580] train loss: 0.0005, train acc: 0.9999, val loss: 0.0109, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26600] train loss: 0.0007, train acc: 0.9999, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26620] train loss: 0.0006, train acc: 0.9998, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26640] train loss: 0.0006, train acc: 0.9998, val loss: 0.0130, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26660] train loss: 0.0006, train acc: 0.9999, val loss: 0.0129, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26680] train loss: 0.0010, train acc: 0.9996, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26700] train loss: 0.0010, train acc: 0.9998, val loss: 0.0131, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26720] train loss: 0.0006, train acc: 0.9999, val loss: 0.0124, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26740] train loss: 0.0008, train acc: 0.9998, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26760] train loss: 0.0013, train acc: 0.9997, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26780] train loss: 0.0006, train acc: 0.9999, val loss: 0.0132, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26800] train loss: 0.0007, train acc: 0.9998, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26820] train loss: 0.0010, train acc: 0.9998, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26840] train loss: 0.0005, train acc: 0.9998, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26860] train loss: 0.0005, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26880] train loss: 0.0004, train acc: 0.9999, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26900] train loss: 0.0006, train acc: 0.9999, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26920] train loss: 0.0012, train acc: 0.9997, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26940] train loss: 0.0009, train acc: 0.9998, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26960] train loss: 0.0011, train acc: 0.9998, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 26980] train loss: 0.0012, train acc: 0.9996, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27000] train loss: 0.0010, train acc: 0.9997, val loss: 0.0131, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27020] train loss: 0.0007, train acc: 0.9998, val loss: 0.0122, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27040] train loss: 0.0005, train acc: 0.9999, val loss: 0.0125, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27060] train loss: 0.0006, train acc: 0.9999, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27080] train loss: 0.0013, train acc: 0.9996, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27100] train loss: 0.0005, train acc: 0.9999, val loss: 0.0117, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27120] train loss: 0.0007, train acc: 0.9999, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27140] train loss: 0.0009, train acc: 0.9999, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27160] train loss: 0.0007, train acc: 0.9999, val loss: 0.0132, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27180] train loss: 0.0007, train acc: 0.9998, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27200] train loss: 0.0006, train acc: 0.9999, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27220] train loss: 0.0007, train acc: 0.9998, val loss: 0.0141, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27240] train loss: 0.0008, train acc: 0.9997, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27260] train loss: 0.0007, train acc: 0.9999, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27280] train loss: 0.0005, train acc: 0.9999, val loss: 0.0125, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27300] train loss: 0.0006, train acc: 0.9999, val loss: 0.0138, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27320] train loss: 0.0006, train acc: 0.9999, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27340] train loss: 0.0006, train acc: 0.9999, val loss: 0.0124, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27360] train loss: 0.0008, train acc: 0.9999, val loss: 0.0123, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27380] train loss: 0.0011, train acc: 0.9996, val loss: 0.0124, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27400] train loss: 0.0008, train acc: 0.9998, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27420] train loss: 0.0006, train acc: 0.9998, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27440] train loss: 0.0008, train acc: 0.9998, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27460] train loss: 0.0009, train acc: 0.9997, val loss: 0.0129, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27480] train loss: 0.0008, train acc: 0.9998, val loss: 0.0132, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27500] train loss: 0.0982, train acc: 0.9790, val loss: 0.0247, val acc: 0.9926  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27520] train loss: 0.0048, train acc: 0.9992, val loss: 0.0067, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27540] train loss: 0.0026, train acc: 0.9993, val loss: 0.0105, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27560] train loss: 0.0022, train acc: 0.9993, val loss: 0.0104, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27580] train loss: 0.0013, train acc: 0.9999, val loss: 0.0112, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27600] train loss: 0.0016, train acc: 0.9997, val loss: 0.0114, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27620] train loss: 0.0021, train acc: 0.9996, val loss: 0.0111, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27640] train loss: 0.0020, train acc: 0.9996, val loss: 0.0116, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27660] train loss: 0.0019, train acc: 0.9996, val loss: 0.0117, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27680] train loss: 0.0016, train acc: 0.9996, val loss: 0.0107, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27700] train loss: 0.0017, train acc: 0.9996, val loss: 0.0137, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27720] train loss: 0.0017, train acc: 0.9996, val loss: 0.0132, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27740] train loss: 0.0008, train acc: 0.9998, val loss: 0.0142, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27760] train loss: 0.0018, train acc: 0.9996, val loss: 0.0136, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27780] train loss: 0.0013, train acc: 0.9997, val loss: 0.0145, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27800] train loss: 0.0006, train acc: 0.9999, val loss: 0.0144, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27820] train loss: 0.0010, train acc: 0.9997, val loss: 0.0138, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27840] train loss: 0.0007, train acc: 0.9999, val loss: 0.0129, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27860] train loss: 0.0009, train acc: 0.9997, val loss: 0.0136, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27880] train loss: 0.0013, train acc: 0.9996, val loss: 0.0135, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27900] train loss: 0.0011, train acc: 0.9997, val loss: 0.0153, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27920] train loss: 0.0012, train acc: 0.9998, val loss: 0.0143, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27940] train loss: 0.0008, train acc: 0.9999, val loss: 0.0147, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27960] train loss: 0.0006, train acc: 0.9999, val loss: 0.0152, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 27980] train loss: 0.0006, train acc: 0.9999, val loss: 0.0130, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28000] train loss: 0.0006, train acc: 0.9999, val loss: 0.0136, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28020] train loss: 0.0011, train acc: 0.9998, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28040] train loss: 0.0007, train acc: 0.9999, val loss: 0.0130, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28060] train loss: 0.0007, train acc: 0.9999, val loss: 0.0143, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28080] train loss: 0.0011, train acc: 0.9997, val loss: 0.0140, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28100] train loss: 0.0012, train acc: 0.9997, val loss: 0.0142, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28120] train loss: 0.0010, train acc: 0.9997, val loss: 0.0130, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28140] train loss: 0.0011, train acc: 0.9998, val loss: 0.0122, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28160] train loss: 0.0011, train acc: 0.9998, val loss: 0.0125, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28180] train loss: 0.0007, train acc: 0.9999, val loss: 0.0133, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28200] train loss: 0.0005, train acc: 0.9999, val loss: 0.0138, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28220] train loss: 0.0005, train acc: 0.9999, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28240] train loss: 0.0006, train acc: 0.9999, val loss: 0.0145, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28260] train loss: 0.0010, train acc: 0.9996, val loss: 0.0152, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28280] train loss: 0.0005, train acc: 0.9999, val loss: 0.0150, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28300] train loss: 0.0011, train acc: 0.9997, val loss: 0.0142, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28320] train loss: 0.0011, train acc: 0.9996, val loss: 0.0135, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28340] train loss: 0.0008, train acc: 0.9998, val loss: 0.0139, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28360] train loss: 0.0006, train acc: 0.9999, val loss: 0.0133, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28380] train loss: 0.0005, train acc: 0.9999, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28400] train loss: 0.0015, train acc: 0.9996, val loss: 0.0128, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28420] train loss: 0.0004, train acc: 1.0000, val loss: 0.0142, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28440] train loss: 0.0007, train acc: 0.9999, val loss: 0.0136, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28460] train loss: 0.0010, train acc: 0.9998, val loss: 0.0143, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28480] train loss: 0.0007, train acc: 0.9999, val loss: 0.0140, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28500] train loss: 0.0009, train acc: 0.9998, val loss: 0.0145, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28520] train loss: 0.0009, train acc: 0.9997, val loss: 0.0130, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28540] train loss: 0.0008, train acc: 0.9999, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28560] train loss: 0.0003, train acc: 0.9999, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28580] train loss: 0.0011, train acc: 0.9997, val loss: 0.0134, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28600] train loss: 0.0013, train acc: 0.9996, val loss: 0.0132, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28620] train loss: 0.0014, train acc: 0.9998, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28640] train loss: 0.0010, train acc: 0.9996, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28660] train loss: 0.0008, train acc: 0.9999, val loss: 0.0112, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28680] train loss: 0.0010, train acc: 0.9998, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28700] train loss: 0.0009, train acc: 0.9998, val loss: 0.0133, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28720] train loss: 0.0006, train acc: 0.9999, val loss: 0.0137, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28740] train loss: 0.0008, train acc: 0.9999, val loss: 0.0135, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28760] train loss: 0.0005, train acc: 0.9999, val loss: 0.0131, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28780] train loss: 0.0002, train acc: 1.0000, val loss: 0.0132, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28800] train loss: 0.0004, train acc: 0.9999, val loss: 0.0131, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28820] train loss: 0.0010, train acc: 0.9997, val loss: 0.0132, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28840] train loss: 0.0007, train acc: 0.9998, val loss: 0.0135, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28860] train loss: 0.0009, train acc: 0.9998, val loss: 0.0133, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28880] train loss: 0.0003, train acc: 1.0000, val loss: 0.0136, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28900] train loss: 0.0005, train acc: 0.9999, val loss: 0.0132, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28920] train loss: 0.0009, train acc: 0.9997, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28940] train loss: 0.0011, train acc: 0.9997, val loss: 0.0133, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28960] train loss: 0.0006, train acc: 0.9999, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 28980] train loss: 0.0013, train acc: 0.9996, val loss: 0.0120, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29000] train loss: 0.0008, train acc: 0.9997, val loss: 0.0130, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29020] train loss: 0.0008, train acc: 0.9998, val loss: 0.0115, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29040] train loss: 0.0010, train acc: 0.9998, val loss: 0.0128, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29060] train loss: 0.0009, train acc: 0.9997, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29080] train loss: 0.0010, train acc: 0.9998, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29100] train loss: 0.0019, train acc: 0.9994, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29120] train loss: 0.0004, train acc: 0.9999, val loss: 0.0125, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29140] train loss: 0.0010, train acc: 0.9998, val loss: 0.0113, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29160] train loss: 0.0014, train acc: 0.9996, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29180] train loss: 0.0004, train acc: 0.9999, val loss: 0.0132, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29200] train loss: 0.0012, train acc: 0.9998, val loss: 0.0132, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29220] train loss: 0.0011, train acc: 0.9997, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29240] train loss: 0.0007, train acc: 0.9999, val loss: 0.0127, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29260] train loss: 0.0007, train acc: 0.9999, val loss: 0.0130, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29280] train loss: 0.0009, train acc: 0.9997, val loss: 0.0119, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29300] train loss: 0.0005, train acc: 0.9999, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29320] train loss: 0.0003, train acc: 1.0000, val loss: 0.0134, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29340] train loss: 0.0009, train acc: 0.9998, val loss: 0.0136, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29360] train loss: 0.0008, train acc: 0.9997, val loss: 0.0132, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29380] train loss: 0.0004, train acc: 0.9999, val loss: 0.0132, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29400] train loss: 0.0014, train acc: 0.9997, val loss: 0.0118, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29420] train loss: 0.0010, train acc: 0.9997, val loss: 0.0129, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29440] train loss: 0.0005, train acc: 0.9999, val loss: 0.0128, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29460] train loss: 0.0015, train acc: 0.9996, val loss: 0.0131, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29480] train loss: 0.0007, train acc: 0.9998, val loss: 0.0108, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29500] train loss: 0.0004, train acc: 0.9999, val loss: 0.0139, val acc: 0.9976  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29520] train loss: 0.0010, train acc: 0.9998, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29540] train loss: 0.0010, train acc: 0.9997, val loss: 0.0114, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29560] train loss: 0.0004, train acc: 1.0000, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29580] train loss: 0.0010, train acc: 0.9997, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29600] train loss: 0.0005, train acc: 0.9999, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29620] train loss: 0.0003, train acc: 1.0000, val loss: 0.0126, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29640] train loss: 0.0010, train acc: 0.9996, val loss: 0.0128, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29660] train loss: 0.0012, train acc: 0.9998, val loss: 0.0141, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29680] train loss: 0.0007, train acc: 0.9999, val loss: 0.0129, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29700] train loss: 0.0012, train acc: 0.9997, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29720] train loss: 0.0005, train acc: 0.9999, val loss: 0.0127, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29740] train loss: 0.0010, train acc: 0.9997, val loss: 0.0140, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29760] train loss: 0.0011, train acc: 0.9997, val loss: 0.0138, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29780] train loss: 0.0013, train acc: 0.9997, val loss: 0.0137, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29800] train loss: 0.0006, train acc: 0.9999, val loss: 0.0126, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29820] train loss: 0.0006, train acc: 0.9999, val loss: 0.0134, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29840] train loss: 0.0009, train acc: 0.9997, val loss: 0.0128, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29860] train loss: 0.0008, train acc: 0.9998, val loss: 0.0125, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29880] train loss: 0.0012, train acc: 0.9996, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29900] train loss: 0.0009, train acc: 0.9998, val loss: 0.0123, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29920] train loss: 0.0011, train acc: 0.9998, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29940] train loss: 0.0009, train acc: 0.9998, val loss: 0.0124, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29960] train loss: 0.0006, train acc: 0.9998, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 29980] train loss: 0.0008, train acc: 0.9999, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30000] train loss: 0.0004, train acc: 0.9999, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30020] train loss: 0.0008, train acc: 0.9999, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30040] train loss: 0.0006, train acc: 0.9999, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30060] train loss: 0.0007, train acc: 0.9998, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30080] train loss: 0.0005, train acc: 0.9999, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30100] train loss: 0.0004, train acc: 0.9999, val loss: 0.0124, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30120] train loss: 0.0013, train acc: 0.9997, val loss: 0.0114, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30140] train loss: 0.0010, train acc: 0.9997, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30160] train loss: 0.0006, train acc: 0.9999, val loss: 0.0122, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30180] train loss: 0.0008, train acc: 0.9999, val loss: 0.0142, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30200] train loss: 0.0003, train acc: 0.9999, val loss: 0.0137, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30220] train loss: 0.0010, train acc: 0.9997, val loss: 0.0135, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30240] train loss: 0.0007, train acc: 0.9999, val loss: 0.0132, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30260] train loss: 0.0008, train acc: 0.9998, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30280] train loss: 0.0010, train acc: 0.9998, val loss: 0.0152, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30300] train loss: 0.0012, train acc: 0.9996, val loss: 0.0129, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30320] train loss: 0.0007, train acc: 0.9999, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30340] train loss: 0.0006, train acc: 0.9999, val loss: 0.0130, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30360] train loss: 0.0010, train acc: 0.9998, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30380] train loss: 0.0007, train acc: 0.9999, val loss: 0.0137, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30400] train loss: 0.0010, train acc: 0.9997, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30420] train loss: 0.0008, train acc: 0.9998, val loss: 0.0127, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30440] train loss: 0.0007, train acc: 0.9999, val loss: 0.0135, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30460] train loss: 0.0004, train acc: 0.9999, val loss: 0.0124, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30480] train loss: 0.0012, train acc: 0.9998, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30500] train loss: 0.0012, train acc: 0.9996, val loss: 0.0115, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30520] train loss: 0.0010, train acc: 0.9997, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30540] train loss: 0.0008, train acc: 0.9998, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30560] train loss: 0.0008, train acc: 0.9998, val loss: 0.0133, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30580] train loss: 0.0009, train acc: 0.9997, val loss: 0.0131, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30600] train loss: 0.0004, train acc: 0.9999, val loss: 0.0127, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30620] train loss: 0.0004, train acc: 0.9999, val loss: 0.0107, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30640] train loss: 0.0007, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30660] train loss: 0.0007, train acc: 0.9996, val loss: 0.0131, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30680] train loss: 0.0005, train acc: 0.9999, val loss: 0.0140, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30700] train loss: 0.0010, train acc: 0.9998, val loss: 0.0128, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30720] train loss: 0.0008, train acc: 0.9997, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30740] train loss: 0.0006, train acc: 0.9999, val loss: 0.0128, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30760] train loss: 0.0008, train acc: 0.9999, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30780] train loss: 0.0007, train acc: 0.9999, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30800] train loss: 0.0007, train acc: 1.0000, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30820] train loss: 0.0011, train acc: 0.9997, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30840] train loss: 0.0007, train acc: 0.9998, val loss: 0.0119, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30860] train loss: 0.0005, train acc: 0.9999, val loss: 0.0130, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30880] train loss: 0.0009, train acc: 0.9997, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30900] train loss: 0.0005, train acc: 0.9999, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30920] train loss: 0.0008, train acc: 0.9999, val loss: 0.0122, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30940] train loss: 0.0011, train acc: 0.9996, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30960] train loss: 0.0009, train acc: 0.9998, val loss: 0.0116, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 30980] train loss: 0.0004, train acc: 1.0000, val loss: 0.0123, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31000] train loss: 0.0006, train acc: 0.9998, val loss: 0.0131, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31020] train loss: 0.0008, train acc: 0.9997, val loss: 0.0125, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31040] train loss: 0.0007, train acc: 0.9999, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31060] train loss: 0.0010, train acc: 0.9998, val loss: 0.0132, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31080] train loss: 0.0011, train acc: 0.9996, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31100] train loss: 0.0015, train acc: 0.9996, val loss: 0.0130, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31120] train loss: 0.0011, train acc: 0.9998, val loss: 0.0126, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31140] train loss: 0.0005, train acc: 0.9999, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31160] train loss: 0.0003, train acc: 0.9999, val loss: 0.0126, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31180] train loss: 0.0011, train acc: 0.9996, val loss: 0.0126, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31200] train loss: 0.0005, train acc: 0.9999, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31220] train loss: 0.0006, train acc: 0.9999, val loss: 0.0125, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31240] train loss: 0.0005, train acc: 0.9999, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31260] train loss: 0.0003, train acc: 1.0000, val loss: 0.0124, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31280] train loss: 0.0007, train acc: 0.9999, val loss: 0.0125, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31300] train loss: 0.0003, train acc: 0.9999, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31320] train loss: 0.0007, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31340] train loss: 0.0004, train acc: 0.9999, val loss: 0.0129, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31360] train loss: 0.0006, train acc: 0.9999, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31380] train loss: 0.0007, train acc: 0.9997, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31400] train loss: 0.0011, train acc: 0.9996, val loss: 0.0125, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31420] train loss: 0.0005, train acc: 0.9999, val loss: 0.0131, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31440] train loss: 0.0009, train acc: 0.9997, val loss: 0.0119, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31460] train loss: 0.0007, train acc: 0.9996, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31480] train loss: 0.0006, train acc: 0.9998, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31500] train loss: 0.0006, train acc: 0.9998, val loss: 0.0131, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31520] train loss: 0.0005, train acc: 1.0000, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31540] train loss: 0.0010, train acc: 0.9996, val loss: 0.0131, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31560] train loss: 0.0004, train acc: 0.9999, val loss: 0.0139, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31580] train loss: 0.0017, train acc: 0.9995, val loss: 0.0127, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31600] train loss: 0.0005, train acc: 0.9999, val loss: 0.0133, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31620] train loss: 0.0010, train acc: 0.9998, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31640] train loss: 0.0010, train acc: 0.9998, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31660] train loss: 0.0003, train acc: 0.9999, val loss: 0.0123, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31680] train loss: 0.0006, train acc: 0.9998, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31700] train loss: 0.0013, train acc: 0.9996, val loss: 0.0123, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31720] train loss: 0.0015, train acc: 0.9996, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31740] train loss: 0.0009, train acc: 0.9998, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31760] train loss: 0.0006, train acc: 0.9999, val loss: 0.0129, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31780] train loss: 0.0007, train acc: 0.9998, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31800] train loss: 0.0007, train acc: 0.9997, val loss: 0.0125, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31820] train loss: 0.0009, train acc: 0.9997, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31840] train loss: 0.0012, train acc: 0.9996, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31860] train loss: 0.0005, train acc: 0.9999, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31880] train loss: 0.0010, train acc: 0.9996, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31900] train loss: 0.0009, train acc: 0.9998, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31920] train loss: 0.0005, train acc: 0.9999, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31940] train loss: 0.0005, train acc: 0.9999, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31960] train loss: 0.0005, train acc: 0.9999, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 31980] train loss: 0.0009, train acc: 0.9998, val loss: 0.0108, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32000] train loss: 0.0003, train acc: 0.9999, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32020] train loss: 0.0012, train acc: 0.9996, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32040] train loss: 0.0011, train acc: 0.9997, val loss: 0.0125, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32060] train loss: 0.0007, train acc: 0.9998, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32080] train loss: 0.0010, train acc: 0.9997, val loss: 0.0120, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32100] train loss: 0.0013, train acc: 0.9995, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32120] train loss: 0.0140, train acc: 0.9962, val loss: 0.0191, val acc: 0.9963  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32140] train loss: 0.0031, train acc: 0.9993, val loss: 0.0047, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32160] train loss: 0.0022, train acc: 0.9995, val loss: 0.0056, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32180] train loss: 0.0010, train acc: 0.9998, val loss: 0.0059, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32200] train loss: 0.0007, train acc: 0.9999, val loss: 0.0069, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32220] train loss: 0.0011, train acc: 0.9997, val loss: 0.0086, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32240] train loss: 0.0008, train acc: 0.9999, val loss: 0.0083, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32260] train loss: 0.0012, train acc: 0.9997, val loss: 0.0096, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32280] train loss: 0.0009, train acc: 0.9996, val loss: 0.0087, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32300] train loss: 0.0006, train acc: 0.9999, val loss: 0.0089, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32320] train loss: 0.0007, train acc: 0.9998, val loss: 0.0102, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32340] train loss: 0.0004, train acc: 0.9999, val loss: 0.0096, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32360] train loss: 0.0003, train acc: 1.0000, val loss: 0.0093, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32380] train loss: 0.0008, train acc: 0.9999, val loss: 0.0099, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32400] train loss: 0.0012, train acc: 0.9996, val loss: 0.0109, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32420] train loss: 0.0008, train acc: 0.9999, val loss: 0.0098, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32440] train loss: 0.0008, train acc: 0.9998, val loss: 0.0102, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32460] train loss: 0.0006, train acc: 0.9999, val loss: 0.0096, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32480] train loss: 0.0007, train acc: 0.9999, val loss: 0.0101, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32500] train loss: 0.0008, train acc: 0.9998, val loss: 0.0109, val acc: 0.9983  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32520] train loss: 0.0009, train acc: 0.9998, val loss: 0.0099, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32540] train loss: 0.0011, train acc: 0.9996, val loss: 0.0100, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32560] train loss: 0.0011, train acc: 0.9996, val loss: 0.0096, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32580] train loss: 0.0007, train acc: 0.9998, val loss: 0.0096, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32600] train loss: 0.0008, train acc: 0.9998, val loss: 0.0105, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32620] train loss: 0.0006, train acc: 0.9999, val loss: 0.0099, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32640] train loss: 0.0006, train acc: 0.9999, val loss: 0.0098, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32660] train loss: 0.0007, train acc: 0.9999, val loss: 0.0099, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32680] train loss: 0.0015, train acc: 0.9996, val loss: 0.0101, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32700] train loss: 0.0006, train acc: 0.9999, val loss: 0.0101, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32720] train loss: 0.0011, train acc: 0.9996, val loss: 0.0105, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32740] train loss: 0.0006, train acc: 0.9999, val loss: 0.0107, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32760] train loss: 0.0007, train acc: 0.9998, val loss: 0.0104, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32780] train loss: 0.0004, train acc: 0.9999, val loss: 0.0104, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32800] train loss: 0.0012, train acc: 0.9996, val loss: 0.0107, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32820] train loss: 0.0007, train acc: 0.9999, val loss: 0.0107, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32840] train loss: 0.0007, train acc: 0.9998, val loss: 0.0110, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32860] train loss: 0.0009, train acc: 0.9998, val loss: 0.0113, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32880] train loss: 0.0006, train acc: 0.9998, val loss: 0.0114, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32900] train loss: 0.0007, train acc: 0.9998, val loss: 0.0110, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32920] train loss: 0.0006, train acc: 0.9998, val loss: 0.0106, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32940] train loss: 0.0006, train acc: 0.9998, val loss: 0.0110, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32960] train loss: 0.0006, train acc: 0.9998, val loss: 0.0103, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 32980] train loss: 0.0005, train acc: 0.9999, val loss: 0.0107, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33000] train loss: 0.0007, train acc: 0.9998, val loss: 0.0108, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33020] train loss: 0.0009, train acc: 0.9997, val loss: 0.0111, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33040] train loss: 0.0011, train acc: 0.9996, val loss: 0.0108, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33060] train loss: 0.0005, train acc: 0.9999, val loss: 0.0104, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33080] train loss: 0.0003, train acc: 1.0000, val loss: 0.0106, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33100] train loss: 0.0008, train acc: 0.9999, val loss: 0.0107, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33120] train loss: 0.0005, train acc: 0.9999, val loss: 0.0111, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33140] train loss: 0.0010, train acc: 0.9996, val loss: 0.0115, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33160] train loss: 0.0012, train acc: 0.9996, val loss: 0.0115, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33180] train loss: 0.0010, train acc: 0.9997, val loss: 0.0110, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33200] train loss: 0.0006, train acc: 0.9998, val loss: 0.0113, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33220] train loss: 0.0007, train acc: 0.9997, val loss: 0.0114, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33240] train loss: 0.0005, train acc: 0.9998, val loss: 0.0108, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33260] train loss: 0.0004, train acc: 1.0000, val loss: 0.0113, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33280] train loss: 0.0005, train acc: 0.9999, val loss: 0.0117, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33300] train loss: 0.0006, train acc: 0.9999, val loss: 0.0109, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33320] train loss: 0.0009, train acc: 0.9997, val loss: 0.0117, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33340] train loss: 0.0005, train acc: 0.9999, val loss: 0.0119, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33360] train loss: 0.0006, train acc: 0.9999, val loss: 0.0114, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33380] train loss: 0.0007, train acc: 0.9997, val loss: 0.0126, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33400] train loss: 0.0009, train acc: 0.9996, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33420] train loss: 0.0007, train acc: 0.9997, val loss: 0.0114, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33440] train loss: 0.0006, train acc: 0.9998, val loss: 0.0113, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33460] train loss: 0.0004, train acc: 1.0000, val loss: 0.0123, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33480] train loss: 0.0014, train acc: 0.9995, val loss: 0.0129, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33500] train loss: 0.0008, train acc: 0.9998, val loss: 0.0116, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33520] train loss: 0.0007, train acc: 0.9999, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33540] train loss: 0.0006, train acc: 0.9999, val loss: 0.0119, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33560] train loss: 0.0009, train acc: 0.9997, val loss: 0.0124, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33580] train loss: 0.0005, train acc: 0.9999, val loss: 0.0126, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33600] train loss: 0.0007, train acc: 0.9998, val loss: 0.0127, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33620] train loss: 0.0011, train acc: 0.9996, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33640] train loss: 0.0007, train acc: 0.9999, val loss: 0.0122, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33660] train loss: 0.0008, train acc: 0.9997, val loss: 0.0133, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33680] train loss: 0.0006, train acc: 0.9999, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33700] train loss: 0.0004, train acc: 0.9999, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33720] train loss: 0.0010, train acc: 0.9997, val loss: 0.0120, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33740] train loss: 0.0006, train acc: 0.9998, val loss: 0.0125, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33760] train loss: 0.0009, train acc: 0.9996, val loss: 0.0128, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33780] train loss: 0.0006, train acc: 0.9999, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33800] train loss: 0.0005, train acc: 0.9998, val loss: 0.0126, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33820] train loss: 0.0003, train acc: 0.9999, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33840] train loss: 0.0006, train acc: 0.9999, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33860] train loss: 0.0006, train acc: 0.9998, val loss: 0.0129, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33880] train loss: 0.0005, train acc: 0.9999, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33900] train loss: 0.0007, train acc: 0.9998, val loss: 0.0119, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33920] train loss: 0.0008, train acc: 0.9997, val loss: 0.0115, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33940] train loss: 0.0006, train acc: 0.9999, val loss: 0.0116, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33960] train loss: 0.0004, train acc: 0.9999, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 33980] train loss: 0.0007, train acc: 0.9997, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34000] train loss: 0.0005, train acc: 0.9999, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34020] train loss: 0.0009, train acc: 0.9998, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34040] train loss: 0.0004, train acc: 0.9999, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34060] train loss: 0.0005, train acc: 0.9998, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34080] train loss: 0.0008, train acc: 0.9999, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34100] train loss: 0.0004, train acc: 0.9999, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34120] train loss: 0.0005, train acc: 0.9999, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34140] train loss: 0.0005, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34160] train loss: 0.0007, train acc: 0.9999, val loss: 0.0108, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34180] train loss: 0.0004, train acc: 0.9999, val loss: 0.0110, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34200] train loss: 0.0005, train acc: 0.9998, val loss: 0.0105, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34220] train loss: 0.0003, train acc: 0.9999, val loss: 0.0108, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34240] train loss: 0.0004, train acc: 0.9999, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34260] train loss: 0.0006, train acc: 0.9999, val loss: 0.0105, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34280] train loss: 0.0012, train acc: 0.9996, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34300] train loss: 0.0004, train acc: 0.9999, val loss: 0.0116, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34320] train loss: 0.0004, train acc: 0.9999, val loss: 0.0107, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34340] train loss: 0.0005, train acc: 0.9999, val loss: 0.0110, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34360] train loss: 0.0002, train acc: 1.0000, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34380] train loss: 0.0006, train acc: 0.9999, val loss: 0.0121, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34400] train loss: 0.0008, train acc: 0.9999, val loss: 0.0120, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34420] train loss: 0.0007, train acc: 0.9998, val loss: 0.0108, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34440] train loss: 0.0009, train acc: 0.9997, val loss: 0.0117, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34460] train loss: 0.0009, train acc: 0.9998, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34480] train loss: 0.0011, train acc: 0.9997, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34500] train loss: 0.0009, train acc: 0.9998, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34520] train loss: 0.0004, train acc: 0.9999, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34540] train loss: 0.0010, train acc: 0.9998, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34560] train loss: 0.0008, train acc: 0.9998, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34580] train loss: 0.0008, train acc: 0.9998, val loss: 0.0114, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34600] train loss: 0.0003, train acc: 0.9999, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34620] train loss: 0.0010, train acc: 0.9997, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34640] train loss: 0.0007, train acc: 0.9997, val loss: 0.0102, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34660] train loss: 0.0006, train acc: 0.9999, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34680] train loss: 0.0005, train acc: 0.9999, val loss: 0.0109, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34700] train loss: 0.0006, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34720] train loss: 0.0004, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34740] train loss: 0.0004, train acc: 0.9999, val loss: 0.0108, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34760] train loss: 0.0004, train acc: 0.9999, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34780] train loss: 0.0005, train acc: 0.9999, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34800] train loss: 0.0007, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34820] train loss: 0.0007, train acc: 0.9998, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34840] train loss: 0.0004, train acc: 0.9999, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34860] train loss: 0.0006, train acc: 0.9998, val loss: 0.0109, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34880] train loss: 0.0007, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34900] train loss: 0.0004, train acc: 0.9999, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34920] train loss: 0.0006, train acc: 0.9999, val loss: 0.0107, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34940] train loss: 0.0008, train acc: 0.9999, val loss: 0.0108, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34960] train loss: 0.0011, train acc: 0.9996, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 34980] train loss: 0.0004, train acc: 0.9999, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35000] train loss: 0.0008, train acc: 0.9997, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35020] train loss: 0.0008, train acc: 0.9998, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35040] train loss: 0.0003, train acc: 1.0000, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35060] train loss: 0.0004, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35080] train loss: 0.0002, train acc: 1.0000, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35100] train loss: 0.0010, train acc: 0.9996, val loss: 0.0105, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35120] train loss: 0.0005, train acc: 0.9998, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35140] train loss: 0.0007, train acc: 0.9998, val loss: 0.0105, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35160] train loss: 0.0007, train acc: 0.9998, val loss: 0.0109, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35180] train loss: 0.0006, train acc: 0.9999, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35200] train loss: 0.0007, train acc: 0.9999, val loss: 0.0108, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35220] train loss: 0.0005, train acc: 0.9999, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35240] train loss: 0.0008, train acc: 0.9997, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35260] train loss: 0.0008, train acc: 0.9998, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35280] train loss: 0.0005, train acc: 0.9999, val loss: 0.0107, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35300] train loss: 0.0007, train acc: 0.9999, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35320] train loss: 0.0006, train acc: 0.9998, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35340] train loss: 0.0007, train acc: 0.9996, val loss: 0.0108, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35360] train loss: 0.0003, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35380] train loss: 0.0007, train acc: 0.9997, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35400] train loss: 0.0008, train acc: 0.9999, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35420] train loss: 0.0005, train acc: 0.9999, val loss: 0.0108, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35440] train loss: 0.0005, train acc: 0.9999, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35460] train loss: 0.0004, train acc: 0.9999, val loss: 0.0110, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35480] train loss: 0.0004, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35500] train loss: 0.0005, train acc: 0.9998, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35520] train loss: 0.0004, train acc: 0.9999, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35540] train loss: 0.0004, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35560] train loss: 0.0012, train acc: 0.9996, val loss: 0.0110, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35580] train loss: 0.0005, train acc: 0.9999, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35600] train loss: 0.0008, train acc: 0.9997, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35620] train loss: 0.0003, train acc: 1.0000, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35640] train loss: 0.0009, train acc: 0.9998, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35660] train loss: 0.0014, train acc: 0.9996, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35680] train loss: 0.0007, train acc: 0.9997, val loss: 0.0125, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35700] train loss: 0.0006, train acc: 0.9998, val loss: 0.0123, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35720] train loss: 0.0006, train acc: 0.9998, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35740] train loss: 0.0006, train acc: 0.9999, val loss: 0.0122, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35760] train loss: 0.0005, train acc: 0.9999, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35780] train loss: 0.0010, train acc: 0.9998, val loss: 0.0131, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35800] train loss: 0.0004, train acc: 0.9999, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35820] train loss: 0.0006, train acc: 0.9999, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35840] train loss: 0.0006, train acc: 0.9998, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35860] train loss: 0.0008, train acc: 0.9998, val loss: 0.0116, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35880] train loss: 0.0005, train acc: 0.9999, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35900] train loss: 0.0003, train acc: 1.0000, val loss: 0.0105, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35920] train loss: 0.0010, train acc: 0.9997, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35940] train loss: 0.0004, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35960] train loss: 0.0005, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 35980] train loss: 0.0007, train acc: 0.9999, val loss: 0.0110, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36000] train loss: 0.0006, train acc: 0.9998, val loss: 0.0110, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36020] train loss: 0.0007, train acc: 0.9999, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36040] train loss: 0.0004, train acc: 1.0000, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36060] train loss: 0.0011, train acc: 0.9997, val loss: 0.0111, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36080] train loss: 0.0008, train acc: 0.9997, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36100] train loss: 0.0004, train acc: 1.0000, val loss: 0.0117, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36120] train loss: 0.0004, train acc: 1.0000, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36140] train loss: 0.0004, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36160] train loss: 0.0006, train acc: 0.9999, val loss: 0.0120, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36180] train loss: 0.0007, train acc: 0.9999, val loss: 0.0122, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36200] train loss: 0.0006, train acc: 0.9999, val loss: 0.0118, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36220] train loss: 0.0007, train acc: 0.9999, val loss: 0.0108, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36240] train loss: 0.0006, train acc: 0.9999, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36260] train loss: 0.0013, train acc: 0.9996, val loss: 0.0126, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36280] train loss: 0.0009, train acc: 0.9997, val loss: 0.0123, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36300] train loss: 0.0005, train acc: 0.9999, val loss: 0.0123, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36320] train loss: 0.0010, train acc: 0.9997, val loss: 0.0133, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36340] train loss: 0.0005, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36360] train loss: 0.0009, train acc: 0.9998, val loss: 0.0121, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36380] train loss: 0.0003, train acc: 1.0000, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36400] train loss: 0.0009, train acc: 0.9996, val loss: 0.0107, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36420] train loss: 0.0005, train acc: 0.9999, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36440] train loss: 0.0009, train acc: 0.9998, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36460] train loss: 0.0009, train acc: 0.9998, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36480] train loss: 0.0008, train acc: 0.9997, val loss: 0.0124, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36500] train loss: 0.0005, train acc: 0.9999, val loss: 0.0104, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36520] train loss: 0.0009, train acc: 0.9997, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36540] train loss: 0.0006, train acc: 0.9999, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36560] train loss: 0.0004, train acc: 0.9999, val loss: 0.0119, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36580] train loss: 0.0008, train acc: 0.9998, val loss: 0.0164, val acc: 0.9973  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36600] train loss: 0.0041, train acc: 0.9986, val loss: 0.0041, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36620] train loss: 0.0020, train acc: 0.9993, val loss: 0.0066, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36640] train loss: 0.0013, train acc: 0.9997, val loss: 0.0073, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36660] train loss: 0.0007, train acc: 0.9999, val loss: 0.0070, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36680] train loss: 0.0009, train acc: 0.9999, val loss: 0.0078, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36700] train loss: 0.0011, train acc: 0.9998, val loss: 0.0082, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36720] train loss: 0.0019, train acc: 0.9995, val loss: 0.0088, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36740] train loss: 0.0011, train acc: 0.9997, val loss: 0.0091, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36760] train loss: 0.0007, train acc: 0.9999, val loss: 0.0094, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36780] train loss: 0.0008, train acc: 0.9999, val loss: 0.0087, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36800] train loss: 0.0007, train acc: 0.9998, val loss: 0.0085, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36820] train loss: 0.0010, train acc: 0.9997, val loss: 0.0087, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36840] train loss: 0.0011, train acc: 0.9996, val loss: 0.0086, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36860] train loss: 0.0010, train acc: 0.9998, val loss: 0.0086, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36880] train loss: 0.0008, train acc: 0.9998, val loss: 0.0081, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36900] train loss: 0.0007, train acc: 0.9997, val loss: 0.0088, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36920] train loss: 0.0005, train acc: 1.0000, val loss: 0.0090, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36940] train loss: 0.0006, train acc: 0.9999, val loss: 0.0085, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36960] train loss: 0.0006, train acc: 0.9998, val loss: 0.0084, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 36980] train loss: 0.0006, train acc: 0.9998, val loss: 0.0091, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37000] train loss: 0.0003, train acc: 1.0000, val loss: 0.0092, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37020] train loss: 0.0008, train acc: 0.9996, val loss: 0.0091, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37040] train loss: 0.0003, train acc: 1.0000, val loss: 0.0091, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37060] train loss: 0.0006, train acc: 0.9999, val loss: 0.0098, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37080] train loss: 0.0004, train acc: 0.9999, val loss: 0.0093, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37100] train loss: 0.0006, train acc: 0.9999, val loss: 0.0095, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37120] train loss: 0.0005, train acc: 0.9999, val loss: 0.0099, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37140] train loss: 0.0010, train acc: 0.9996, val loss: 0.0095, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37160] train loss: 0.0009, train acc: 0.9997, val loss: 0.0092, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37180] train loss: 0.0006, train acc: 0.9998, val loss: 0.0088, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37200] train loss: 0.0005, train acc: 0.9998, val loss: 0.0095, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37220] train loss: 0.0005, train acc: 0.9999, val loss: 0.0095, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37240] train loss: 0.0004, train acc: 0.9999, val loss: 0.0098, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37260] train loss: 0.0009, train acc: 0.9996, val loss: 0.0098, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37280] train loss: 0.0005, train acc: 0.9999, val loss: 0.0091, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37300] train loss: 0.0005, train acc: 0.9999, val loss: 0.0087, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37320] train loss: 0.0005, train acc: 0.9999, val loss: 0.0090, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37340] train loss: 0.0008, train acc: 0.9998, val loss: 0.0089, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37360] train loss: 0.0006, train acc: 1.0000, val loss: 0.0091, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37380] train loss: 0.0005, train acc: 1.0000, val loss: 0.0098, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37400] train loss: 0.0004, train acc: 0.9999, val loss: 0.0104, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37420] train loss: 0.0009, train acc: 0.9996, val loss: 0.0103, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37440] train loss: 0.0008, train acc: 0.9998, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37460] train loss: 0.0009, train acc: 0.9997, val loss: 0.0103, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37480] train loss: 0.0010, train acc: 0.9997, val loss: 0.0103, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37500] train loss: 0.0010, train acc: 0.9997, val loss: 0.0105, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37520] train loss: 0.0005, train acc: 0.9999, val loss: 0.0104, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37540] train loss: 0.0008, train acc: 0.9999, val loss: 0.0101, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37560] train loss: 0.0006, train acc: 0.9999, val loss: 0.0103, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37580] train loss: 0.0006, train acc: 0.9999, val loss: 0.0103, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37600] train loss: 0.0005, train acc: 0.9999, val loss: 0.0105, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37620] train loss: 0.0007, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37640] train loss: 0.0004, train acc: 0.9999, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37660] train loss: 0.0006, train acc: 0.9999, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37680] train loss: 0.0005, train acc: 0.9999, val loss: 0.0097, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37700] train loss: 0.0003, train acc: 1.0000, val loss: 0.0097, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37720] train loss: 0.0006, train acc: 0.9999, val loss: 0.0099, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37740] train loss: 0.0002, train acc: 1.0000, val loss: 0.0094, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37760] train loss: 0.0011, train acc: 0.9996, val loss: 0.0099, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37780] train loss: 0.0011, train acc: 0.9996, val loss: 0.0096, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37800] train loss: 0.0008, train acc: 0.9997, val loss: 0.0100, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37820] train loss: 0.0007, train acc: 0.9998, val loss: 0.0100, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37840] train loss: 0.0012, train acc: 0.9996, val loss: 0.0096, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37860] train loss: 0.0006, train acc: 0.9998, val loss: 0.0101, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37880] train loss: 0.0005, train acc: 0.9999, val loss: 0.0100, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37900] train loss: 0.0009, train acc: 0.9996, val loss: 0.0094, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37920] train loss: 0.0003, train acc: 0.9999, val loss: 0.0101, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37940] train loss: 0.0005, train acc: 0.9999, val loss: 0.0103, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37960] train loss: 0.0006, train acc: 0.9999, val loss: 0.0107, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 37980] train loss: 0.0010, train acc: 0.9997, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38000] train loss: 0.0008, train acc: 0.9998, val loss: 0.0098, val acc: 0.9987  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38020] train loss: 0.0005, train acc: 0.9999, val loss: 0.0089, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38040] train loss: 0.0007, train acc: 0.9998, val loss: 0.0092, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38060] train loss: 0.0007, train acc: 0.9996, val loss: 0.0109, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38080] train loss: 0.0011, train acc: 0.9996, val loss: 0.0114, val acc: 0.9990  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38100] train loss: 0.0008, train acc: 0.9997, val loss: 0.0109, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38120] train loss: 0.0012, train acc: 0.9996, val loss: 0.0110, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38140] train loss: 0.0005, train acc: 0.9999, val loss: 0.0114, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38160] train loss: 0.0005, train acc: 0.9999, val loss: 0.0111, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38180] train loss: 0.0012, train acc: 0.9997, val loss: 0.0105, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38200] train loss: 0.0008, train acc: 0.9996, val loss: 0.0099, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38220] train loss: 0.0011, train acc: 0.9997, val loss: 0.0093, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38240] train loss: 0.0006, train acc: 0.9999, val loss: 0.0101, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38260] train loss: 0.0005, train acc: 0.9999, val loss: 0.0100, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38280] train loss: 0.0005, train acc: 0.9999, val loss: 0.0102, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38300] train loss: 0.0004, train acc: 0.9999, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38320] train loss: 0.0005, train acc: 0.9999, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38340] train loss: 0.0007, train acc: 0.9997, val loss: 0.0108, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38360] train loss: 0.0006, train acc: 0.9999, val loss: 0.0103, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38380] train loss: 0.0007, train acc: 0.9998, val loss: 0.0101, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38400] train loss: 0.0011, train acc: 0.9996, val loss: 0.0095, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38420] train loss: 0.0003, train acc: 1.0000, val loss: 0.0109, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38440] train loss: 0.0003, train acc: 1.0000, val loss: 0.0101, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38460] train loss: 0.0013, train acc: 0.9995, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38480] train loss: 0.0010, train acc: 0.9997, val loss: 0.0101, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38500] train loss: 0.0005, train acc: 0.9999, val loss: 0.0097, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38520] train loss: 0.0012, train acc: 0.9996, val loss: 0.0091, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38540] train loss: 0.0005, train acc: 0.9999, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38560] train loss: 0.0009, train acc: 0.9998, val loss: 0.0112, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38580] train loss: 0.0003, train acc: 0.9999, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38600] train loss: 0.0007, train acc: 0.9997, val loss: 0.0100, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38620] train loss: 0.0008, train acc: 0.9999, val loss: 0.0100, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38640] train loss: 0.0005, train acc: 0.9999, val loss: 0.0099, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38660] train loss: 0.0008, train acc: 0.9998, val loss: 0.0089, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38680] train loss: 0.0007, train acc: 0.9998, val loss: 0.0084, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38700] train loss: 0.0005, train acc: 0.9999, val loss: 0.0096, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38720] train loss: 0.0007, train acc: 0.9999, val loss: 0.0096, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38740] train loss: 0.0010, train acc: 0.9998, val loss: 0.0078, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38760] train loss: 0.0004, train acc: 0.9999, val loss: 0.0083, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38780] train loss: 0.0006, train acc: 0.9999, val loss: 0.0090, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38800] train loss: 0.0006, train acc: 0.9999, val loss: 0.0085, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38820] train loss: 0.0005, train acc: 0.9999, val loss: 0.0095, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38840] train loss: 0.0006, train acc: 0.9998, val loss: 0.0081, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38860] train loss: 0.0003, train acc: 1.0000, val loss: 0.0093, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38880] train loss: 0.0006, train acc: 0.9998, val loss: 0.0107, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38900] train loss: 0.0008, train acc: 0.9998, val loss: 0.0088, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38920] train loss: 0.0006, train acc: 0.9998, val loss: 0.0066, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38940] train loss: 0.0006, train acc: 0.9998, val loss: 0.0088, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38960] train loss: 0.0004, train acc: 0.9999, val loss: 0.0077, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 38980] train loss: 0.0006, train acc: 0.9999, val loss: 0.0098, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39000] train loss: 0.0004, train acc: 1.0000, val loss: 0.0097, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39020] train loss: 0.0002, train acc: 1.0000, val loss: 0.0093, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39040] train loss: 0.0005, train acc: 0.9998, val loss: 0.0099, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39060] train loss: 0.0006, train acc: 0.9999, val loss: 0.0105, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39080] train loss: 0.0007, train acc: 0.9998, val loss: 0.0095, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39100] train loss: 0.0004, train acc: 0.9999, val loss: 0.0097, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39120] train loss: 0.0004, train acc: 0.9999, val loss: 0.0094, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39140] train loss: 0.0005, train acc: 0.9999, val loss: 0.0103, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39160] train loss: 0.0004, train acc: 0.9999, val loss: 0.0107, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39180] train loss: 0.0007, train acc: 0.9999, val loss: 0.0096, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39200] train loss: 0.0005, train acc: 0.9999, val loss: 0.0102, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39220] train loss: 0.0011, train acc: 0.9997, val loss: 0.0094, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39240] train loss: 0.0004, train acc: 0.9999, val loss: 0.0099, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39260] train loss: 0.0006, train acc: 0.9997, val loss: 0.0084, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39280] train loss: 0.0007, train acc: 0.9998, val loss: 0.0092, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39300] train loss: 0.0003, train acc: 0.9999, val loss: 0.0083, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39320] train loss: 0.0008, train acc: 0.9997, val loss: 0.0101, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39340] train loss: 0.0008, train acc: 0.9997, val loss: 0.0091, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39360] train loss: 0.0007, train acc: 0.9999, val loss: 0.0087, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39380] train loss: 0.0010, train acc: 0.9997, val loss: 0.0085, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39400] train loss: 0.0008, train acc: 0.9997, val loss: 0.0084, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39420] train loss: 0.0010, train acc: 0.9996, val loss: 0.0103, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39440] train loss: 0.0007, train acc: 0.9999, val loss: 0.0100, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39460] train loss: 0.0012, train acc: 0.9994, val loss: 0.0076, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39480] train loss: 0.0013, train acc: 0.9997, val loss: 0.0095, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39500] train loss: 0.0007, train acc: 0.9999, val loss: 0.0090, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39520] train loss: 0.0006, train acc: 0.9999, val loss: 0.0104, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39540] train loss: 0.0005, train acc: 0.9999, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39560] train loss: 0.0010, train acc: 0.9996, val loss: 0.0099, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39580] train loss: 0.0006, train acc: 0.9999, val loss: 0.0105, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39600] train loss: 0.0006, train acc: 0.9999, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39620] train loss: 0.0007, train acc: 0.9999, val loss: 0.0096, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39640] train loss: 0.0007, train acc: 0.9999, val loss: 0.0085, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39660] train loss: 0.0005, train acc: 0.9999, val loss: 0.0113, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39680] train loss: 0.0009, train acc: 0.9998, val loss: 0.0096, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39700] train loss: 0.0006, train acc: 0.9999, val loss: 0.0090, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39720] train loss: 0.0006, train acc: 1.0000, val loss: 0.0097, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39740] train loss: 0.0006, train acc: 0.9999, val loss: 0.0102, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39760] train loss: 0.0005, train acc: 0.9998, val loss: 0.0092, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39780] train loss: 0.0005, train acc: 0.9999, val loss: 0.0107, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39800] train loss: 0.0011, train acc: 0.9995, val loss: 0.0103, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39820] train loss: 0.0004, train acc: 0.9999, val loss: 0.0115, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39840] train loss: 0.0007, train acc: 0.9998, val loss: 0.0104, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39860] train loss: 0.0008, train acc: 0.9996, val loss: 0.0106, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39880] train loss: 0.0006, train acc: 0.9998, val loss: 0.0103, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39900] train loss: 0.0011, train acc: 0.9996, val loss: 0.0100, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39920] train loss: 0.0014, train acc: 0.9996, val loss: 0.0092, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39940] train loss: 0.0005, train acc: 0.9999, val loss: 0.0097, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39960] train loss: 0.0011, train acc: 0.9996, val loss: 0.0109, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 39980] train loss: 0.0007, train acc: 0.9999, val loss: 0.0104, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n",
      "[Epoch: 40000] train loss: 0.0005, train acc: 0.9999, val loss: 0.0100, val acc: 0.9993  (best train acc: 1.0000, best val acc: 0.9993, best train loss: 0.0001  @ epoch 20977 )\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       154\n",
      "           1       1.00      1.00      1.00      2810\n",
      "\n",
      "    accuracy                           1.00      2964\n",
      "   macro avg       1.00      1.00      1.00      2964\n",
      "weighted avg       1.00      1.00      1.00      2964\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr              = 0.001\n",
    "epochs          = 40000\n",
    "weight_decay    = 0.0005\n",
    "classes         = ['P', 'U']\n",
    "\n",
    "model = GNN7L_Sage(dataset)\n",
    "preds = train(model, dataset, epochs, lr, weight_decay, classes, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       154\n",
      "           1       1.00      1.00      1.00      2810\n",
      "\n",
      "    accuracy                           1.00      2964\n",
      "   macro avg       1.00      1.00      1.00      2964\n",
      "weighted avg       1.00      1.00      1.00      2964\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, probs, model = predict_from_saved_model(model_name + '_40000_0_0005', dataset, classes, save_to_file=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3e417715d34ce8ad701b19feadb755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Precision on top 25 : 0.72\n",
      "[+] Precision on top 50 : 0.66\n",
      "[+] Precision on top 100 : 0.67\n",
      "[+] Precision on top 200 : 0.625\n",
      "[+] Precision on top 500 : 0.53\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('precision_positive_genes.csv') \n",
    "n_positives = n_positives = df['n_positives'][df[disease_Id].idxmax()]\n",
    "\n",
    "preds, probs, model = predict_from_saved_model(model_name+'_40000_0_0005', dataset, classes, save_to_file=False, plot_results=False)\n",
    "\n",
    "ranking = get_ranking(model, dataset, preds, probs, disease_Id, n_positive=n_positives, explanation_nodes_ratio=1, masks_for_seed=10, G=G)\n",
    "\n",
    "### Save ranking to file\n",
    "filename = PATH_TO_RANKINGS + disease_Id + '_' + str(n_positives) + '_new_rankings.txt'\n",
    "with open(filename, 'w') as f:\n",
    "    for line in ranking:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "cuts = [25, 50, 100, 200, 500]\n",
    "for k in cuts:\n",
    "    precision = validate_with_extended_dataset(ranking[:k], disease_Id, save_ranking_to_file=False)\n",
    "    print('[+] Precision on top', k, ':', precision/k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking - No LP intersection\n",
    "Considering all genes in explanations subgraph with score >= mean score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('precision_positive_genes.csv') \n",
    "n_positives = n_positives = df['n_positives'][df[disease_Id].idxmax()]\n",
    "\n",
    "preds, probs, model = predict_from_saved_model(model_name+'_40000_0_0005', dataset, classes, save_to_file=False, plot_results=False)\n",
    "\n",
    "ranking = get_ranking_no_LP_intersection(model, dataset, preds, probs, disease_Id, n_positive=n_positives, explanation_nodes_ratio=1, masks_for_seed=10, G=G)\n",
    "\n",
    "### Save ranking to file\n",
    "filename = PATH_TO_RANKINGS + disease_Id + '_' + str(n_positives) + '_new_rankings_no_LP_intersection.txt'\n",
    "with open(filename, 'w') as f:\n",
    "    for line in ranking:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "cuts = [25, 50, 100, 200, 500]\n",
    "for k in cuts:\n",
    "    precision = validate_with_extended_dataset_no_LP(ranking[:k], disease_Id, save_ranking_to_file=True)\n",
    "    print('[+] Precision on top', k, ':', precision/k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All positive genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] 672 positive nodes found in the graph\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd130a172fbd4c00b4a6a1f89200cf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranking = get_ranking_from_all_positives(model, dataset, preds, disease_Id, explanation_nodes_ratio=1, masks_for_seed=5, G=G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save ranking to file\n",
    "filename = PATH_TO_RANKINGS + disease_Id + '_all_positives_new_ranking.txt'\n",
    "with open(filename, 'w') as f:\n",
    "     for line in ranking:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Precision on top 25 : 0.68\n",
      "[+] Precision on top 50 : 0.72\n",
      "[+] Precision on top 100 : 0.66\n",
      "[+] Precision on top 200 : 0.645\n",
      "[+] Precision on top 500 : 0.574\n"
     ]
    }
   ],
   "source": [
    "cuts = [25, 50, 100, 200, 500]\n",
    "for k in cuts:\n",
    "    precision = validate_with_extended_dataset(ranking[:k], disease_Id, save_ranking_to_file=False)\n",
    "    print('[+] Precision on top', k, ':', precision/k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('xgdag')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95e74f98ff60f14b2a40b3a815b098ff5be6a65f27ff7ed052a7e49eb675036c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
